{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3 notebook for neural network\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import statistics\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import plot_model\n",
    "import IPython.display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import importlib\n",
    "import sys\n",
    "import pickle\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "from random import shuffle\n",
    "\n",
    "# https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "we = importlib.import_module(\"word_embeddings\")\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Global Parameters \"\"\"\n",
    "# Load some data\n",
    "wordEmbedDict = we.getWordEmbeddingDict() # Load the dictionary\n",
    "\n",
    "# Labels\n",
    "top_20 = sorted(['AskReddit', 'leagueoflegends', 'nba', 'funny', 'pics', 'nfl', 'pcmasterrace', \\\n",
    "          'videos', 'news', 'todayilearned', 'DestinyTheGame', 'worldnews', 'soccer', \\\n",
    "          'DotA2', 'AdviceAnimals', 'WTF', 'GlobalOffensive', 'hockey', 'movies', 'SquaredCircle'])\n",
    "\n",
    "# Indices of our desired data\n",
    "TRUE_LABEL = 8 # Index of the true label, hard coded\n",
    "BODY_INDEX = 17 # Index of the reddit comment, hard coded\n",
    "\n",
    "# Neural Network Parameters\n",
    "NUM_SUBREDDITS = len(top_20)\n",
    "NUM_FEATURES = 300 # length returned from embedding\n",
    "NUM_EXAMPLES = 9999 # Arbitrary, choose however many we want to grab from the dataset\n",
    "NUM_EPOCHS = 500 \n",
    "NUM_HIDDEN_NEURONS = 20\n",
    "NUM_LAYERS = 15\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "SUBREDDIT = \"leagueoflegends\" # used for debugging,delete later\n",
    "unparsed = \"./data/condensed_dataset_SMALL.pkl\" # will change this so we can just call the whole pkl set\n",
    "\n",
    "# Encoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(top_20) # Encodes the NUM_SUBREDDITS subreddits\n",
    "\n",
    "# Seed\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\"\"\" \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Helper Functions'''\n",
    "\n",
    "# Normalization of dataset\n",
    "\n",
    "# Get mean of a column feature\n",
    "def getMean(column):\n",
    "    sum = 0\n",
    "    n = len(column)\n",
    "    for i in range(n):\n",
    "        sum += column.iloc[i]\n",
    "    mean = sum / float(n)\n",
    "    return mean\n",
    "\n",
    "def getVariance(column, mean):\n",
    "    squareMeanSum = 0\n",
    "    n = len(column)\n",
    "    for i in range(n):\n",
    "        squareMeanSum += (column.iloc[i] - mean)**2\n",
    "    var = math.sqrt(squareMeanSum / float(n))\n",
    "    return var\n",
    "\n",
    "def normalizeSet(set):\n",
    "    numRow = len(set.index)\n",
    "    numCol = len(set.columns)\n",
    "    for col in range(numCol):\n",
    "        column = set.iloc[:,col]\n",
    "        mean = getMean(column)\n",
    "        var = getVariance(column, mean)\n",
    "        \n",
    "        for row in range(numRow):\n",
    "            set.iloc[row, col] = float(set.iloc[row, col] - mean) / var\n",
    "    return set\n",
    "\n",
    "# @param dir: string, directory of pickle data\n",
    "# @return dataset: unpickled dataset\n",
    "def loadPickleData(dir):\n",
    "    with open(dir, 'rb') as f:\n",
    "        dataset = pickle.load(f)\n",
    "    return dataset\n",
    "\n",
    "# Returns [X, Y] with m examples\n",
    "def loadData(pickleDir, m):\n",
    "    pickle = loadPickleData(pickleDir)\n",
    "    return vectorizeDataSet(pickle, m)\n",
    "\n",
    "def stripNonAlpha(word):\n",
    "    word = re.sub(r'\\W+', '', word)\n",
    "    return word\n",
    "\n",
    "def vectorizeWord(word):\n",
    "    word = stripNonAlpha(word)\n",
    "    keyset = wordEmbedDict.keys() # words in the dictionary\n",
    "    zeroVec = np.zeros((1, NUM_FEATURES))\n",
    "    vWord = pd.DataFrame(zeroVec)\n",
    "    \n",
    "    if word in keyset:\n",
    "        vWord = pd.DataFrame(wordEmbedDict[word]).transpose()\n",
    "    return vWord # returns zero vector if the word is not in the dictionary\n",
    "\n",
    "def vectorizeComment(body):\n",
    "    vComment = np.zeros((1, NUM_FEATURES))\n",
    "    vComment = pd.DataFrame(vComment)\n",
    "    words = body.split()\n",
    "#     print(vComment)\n",
    "    \n",
    "    numWords = 0\n",
    "    for word in words:\n",
    "        vWord = vectorizeWord(word)\n",
    "        numWords += 1\n",
    "        vComment = vComment + vWord\n",
    "    vComNP = vComment.values\n",
    "    vComScaled = vComNP * (1/float(numWords))\n",
    "    vComScaled = pd.DataFrame(vComScaled)\n",
    "    return vComScaled\n",
    "\n",
    "# Encodes a subreddit string into an unrolled one-hot pandas vector\n",
    "def oneHotEncode(subreddit):\n",
    "    #   https://machinelearningmastery.com/multi-class-classification-tutorial-keras-deep-learning-library/\n",
    "    encoded_Y = encoder.transform([subreddit])[0] # get the integer category\n",
    "    \n",
    "    oneHot = [0 for _ in range(NUM_SUBREDDITS)]\n",
    "    oneHot[encoded_Y] = 1\n",
    "    pandasOneHot = pd.DataFrame(oneHot)\n",
    "    \n",
    "    return pandasOneHot.transpose()\n",
    "    \n",
    "    \n",
    "#TODO: check if seed is bad??\n",
    "#TODO: limit number of features \n",
    "def vectorizeDataSet(data, m):\n",
    "    data = pd.DataFrame(data)\n",
    "    data = data.sample(frac=1, random_state=seed).reset_index(drop=True) # Shuffles data\n",
    "    \n",
    "    comments = data.pop(BODY_INDEX)\n",
    "    true_labels = data.pop(TRUE_LABEL)\n",
    "    \n",
    "    unrollComment = comments[0]\n",
    "    X = vectorizeComment(unrollComment)\n",
    "    firstSubreddit = true_labels[0]\n",
    "    Y = oneHotEncode(firstSubreddit)\n",
    "\n",
    "    # For each example in old data set, get the actual comment and featurize it into X\n",
    "    # Also get unrolled true label\n",
    "    for i in range(1, m):\n",
    "        comment = comments[i]\n",
    "        example = vectorizeComment(comment)\n",
    "        subreddit = true_labels[i]\n",
    "        oneHot = oneHotEncode(subreddit)\n",
    "        \n",
    "        X = pd.concat([X, example])\n",
    "        Y = pd.concat([Y, oneHot])\n",
    "        \n",
    "    X_scaled = preprocessing.StandardScaler().fit_transform(X)\n",
    "    X_scaled_df = pd.DataFrame(X_scaled)\n",
    "    X_scaled_df.reset_index(drop=True, inplace=True)\n",
    "    Y.reset_index(drop=True, inplace=True)\n",
    "    concat = pd.concat([X_scaled_df, Y], axis=1)\n",
    "    return concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset\n",
    "#https://stackoverflow.com/questions/38250710/how-to-split-data-into-3-sets-train-validation-and-test/38251213#38251213\n",
    "def train_validate_test_split(df, train_percent=.9, validate_percent=.05, seed=seed):\n",
    "    m = len(df.index)\n",
    "    \n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[:train_end]\n",
    "    validate = df.iloc[train_end:validate_end]\n",
    "    test = df.loc[validate_end:]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 57s, sys: 922 ms, total: 6min 57s\n",
      "Wall time: 6min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = loadData(unparsed, NUM_EXAMPLES)\n",
    "train, validate, test = train_validate_test_split(df)\n",
    "\n",
    "train_labels = train.iloc[:, NUM_FEATURES:]\n",
    "validate_labels = validate.iloc[:, NUM_FEATURES:]\n",
    "test_labels = test.iloc[:, NUM_FEATURES:]\n",
    "\n",
    "train = train.iloc[:, :NUM_FEATURES]\n",
    "validate = validate.iloc[:, :NUM_FEATURES]\n",
    "test = test.iloc[:, :NUM_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.367342</td>\n",
       "      <td>1.308372</td>\n",
       "      <td>0.201091</td>\n",
       "      <td>-3.792920</td>\n",
       "      <td>1.512685</td>\n",
       "      <td>-1.171437</td>\n",
       "      <td>-69.51420</td>\n",
       "      <td>4.771135</td>\n",
       "      <td>0.642789</td>\n",
       "      <td>-8.226592</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.128425</td>\n",
       "      <td>2.949559</td>\n",
       "      <td>-9.924261</td>\n",
       "      <td>-14.220757</td>\n",
       "      <td>2.549121</td>\n",
       "      <td>-0.092738</td>\n",
       "      <td>-258.15574</td>\n",
       "      <td>21.234065</td>\n",
       "      <td>1.738370</td>\n",
       "      <td>-24.388043</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.771319</td>\n",
       "      <td>-1.761555</td>\n",
       "      <td>-3.291630</td>\n",
       "      <td>-19.368265</td>\n",
       "      <td>6.209984</td>\n",
       "      <td>-4.717876</td>\n",
       "      <td>-413.18892</td>\n",
       "      <td>38.096338</td>\n",
       "      <td>5.955578</td>\n",
       "      <td>-32.400210</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.386540</td>\n",
       "      <td>0.150851</td>\n",
       "      <td>-1.026398</td>\n",
       "      <td>-5.580354</td>\n",
       "      <td>2.035692</td>\n",
       "      <td>-4.830088</td>\n",
       "      <td>-77.26690</td>\n",
       "      <td>4.216888</td>\n",
       "      <td>0.398812</td>\n",
       "      <td>-10.544630</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-2.028093</td>\n",
       "      <td>4.679899</td>\n",
       "      <td>-2.142423</td>\n",
       "      <td>-3.440545</td>\n",
       "      <td>-1.290550</td>\n",
       "      <td>0.699776</td>\n",
       "      <td>-117.00810</td>\n",
       "      <td>7.079300</td>\n",
       "      <td>1.763391</td>\n",
       "      <td>-11.121207</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 320 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2          3         4         5          6   \\\n",
       "0  0.367342  1.308372  0.201091  -3.792920  1.512685 -1.171437  -69.51420   \n",
       "0 -2.128425  2.949559 -9.924261 -14.220757  2.549121 -0.092738 -258.15574   \n",
       "0 -4.771319 -1.761555 -3.291630 -19.368265  6.209984 -4.717876 -413.18892   \n",
       "0 -4.386540  0.150851 -1.026398  -5.580354  2.035692 -4.830088  -77.26690   \n",
       "0 -2.028093  4.679899 -2.142423  -3.440545 -1.290550  0.699776 -117.00810   \n",
       "\n",
       "          7         8          9  ...  10  11  12  13  14  15  16  17  18  19  \n",
       "0   4.771135  0.642789  -8.226592 ...   0   0   0   0   0   0   0   0   0   0  \n",
       "0  21.234065  1.738370 -24.388043 ...   0   0   1   0   0   0   0   0   0   0  \n",
       "0  38.096338  5.955578 -32.400210 ...   0   0   0   0   0   0   0   0   0   1  \n",
       "0   4.216888  0.398812 -10.544630 ...   0   0   0   0   0   0   0   0   0   0  \n",
       "0   7.079300  1.763391 -11.121207 ...   1   0   0   0   0   0   0   0   0   0  \n",
       "\n",
       "[5 rows x 320 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# # Save the dataframe as a pickle file to be read later\n",
    "# df.to_pickle(\"./data/pandas-pickle-small.pkl\")\n",
    "\n",
    "# check if potentially overwriting data with the same feature everytime\n",
    "unpickled = pd.read_pickle(\"./data/pandas-pickle-small.pkl\")\n",
    "unpickled.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 21.7 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Check softmax output (final layer output)\n",
    "# Check gradients inside the keras model built in function\n",
    "# Neural network function\n",
    "def build_nn(hidden_layer_sizes):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # Input layer\n",
    "    model.add(layers.Dense(hidden_layer_sizes[0], input_dim=NUM_FEATURES, activation='relu'))\n",
    "\n",
    "    # Conv1d Layer to fix high variance\n",
    "#     model.add(layers.Conv1D(kernel_size = (10),strides=10,filters=2, input_shape=(hidden_layer_sizes[0],NUM_FEATURES),kernel_initializer= 'uniform',activation='relu'))\n",
    "    \n",
    "#      https://datascience.stackexchange.com/questions/19407/keras-built-in-multi-layer-shortcut\n",
    "#     Hidden layers\n",
    "    for size in hidden_layer_sizes[1:]:\n",
    "        model.add(layers.Dense(size, activation='relu'))\n",
    "        \n",
    "    # Fixes somethings for some reason\n",
    "#     model.add(layers.Flatten())\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(layers.Dense(NUM_SUBREDDITS, activation='softmax'))\n",
    "    \n",
    "    # Optimizer. Can change this to whatever we want\n",
    "    optimizer = tf.keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy', 'categorical_crossentropy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_186 (Dense)            (None, 20)                6020      \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 20)                420       \n",
      "=================================================================\n",
      "Total params: 12,320\n",
      "Trainable params: 12,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "CPU times: user 766 ms, sys: 31.2 ms, total: 797 ms\n",
      "Wall time: 800 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Build the model\n",
    "# Features might be an issue, pick different subreddits\n",
    "# potentially try out CNN with matrix word embedding without combined word embedding\n",
    "sizes_list = [NUM_HIDDEN_NEURONS for i in range(NUM_LAYERS)]\n",
    "nn_model = build_nn(sizes_list)\n",
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8999 samples, validate on 499 samples\n",
      "Epoch 1/500\n",
      "8999/8999 [==============================] - 2s 232us/sample - loss: 2.8774 - acc: 0.0765 - categorical_crossentropy: 2.8774 - val_loss: 2.7412 - val_acc: 0.0701 - val_categorical_crossentropy: 2.7412\n",
      "Epoch 2/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 2.6526 - acc: 0.1003 - categorical_crossentropy: 2.6526 - val_loss: 2.6473 - val_acc: 0.0862 - val_categorical_crossentropy: 2.6473\n",
      "Epoch 3/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 2.5938 - acc: 0.1110 - categorical_crossentropy: 2.5938 - val_loss: 2.6238 - val_acc: 0.1022 - val_categorical_crossentropy: 2.6238\n",
      "Epoch 4/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 2.5527 - acc: 0.1202 - categorical_crossentropy: 2.5527 - val_loss: 2.6213 - val_acc: 0.1022 - val_categorical_crossentropy: 2.6213\n",
      "Epoch 5/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 2.5175 - acc: 0.1276 - categorical_crossentropy: 2.5175 - val_loss: 2.6053 - val_acc: 0.1042 - val_categorical_crossentropy: 2.6053\n",
      "Epoch 6/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 2.4800 - acc: 0.1475 - categorical_crossentropy: 2.4800 - val_loss: 2.6485 - val_acc: 0.1042 - val_categorical_crossentropy: 2.6485\n",
      "Epoch 7/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 2.4490 - acc: 0.1536 - categorical_crossentropy: 2.4490 - val_loss: 2.6076 - val_acc: 0.1483 - val_categorical_crossentropy: 2.6076\n",
      "Epoch 8/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 2.4079 - acc: 0.1645 - categorical_crossentropy: 2.4079 - val_loss: 2.5399 - val_acc: 0.1603 - val_categorical_crossentropy: 2.5399\n",
      "Epoch 9/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 2.3566 - acc: 0.1736 - categorical_crossentropy: 2.3566 - val_loss: 2.4735 - val_acc: 0.1463 - val_categorical_crossentropy: 2.4735\n",
      "Epoch 10/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 2.3148 - acc: 0.1805 - categorical_crossentropy: 2.3148 - val_loss: 2.4543 - val_acc: 0.1383 - val_categorical_crossentropy: 2.4543\n",
      "Epoch 11/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 2.2780 - acc: 0.1967 - categorical_crossentropy: 2.2780 - val_loss: 2.4888 - val_acc: 0.1603 - val_categorical_crossentropy: 2.4888\n",
      "Epoch 12/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 2.2504 - acc: 0.2098 - categorical_crossentropy: 2.2504 - val_loss: 2.4712 - val_acc: 0.1603 - val_categorical_crossentropy: 2.4712\n",
      "Epoch 13/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 2.2179 - acc: 0.2145 - categorical_crossentropy: 2.2179 - val_loss: 2.4719 - val_acc: 0.1643 - val_categorical_crossentropy: 2.4719\n",
      "Epoch 14/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 2.1931 - acc: 0.2171 - categorical_crossentropy: 2.1931 - val_loss: 2.4939 - val_acc: 0.1743 - val_categorical_crossentropy: 2.4939\n",
      "Epoch 15/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 2.1827 - acc: 0.2267 - categorical_crossentropy: 2.1827 - val_loss: 2.4739 - val_acc: 0.1924 - val_categorical_crossentropy: 2.4739\n",
      "Epoch 16/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 2.1499 - acc: 0.2372 - categorical_crossentropy: 2.1499 - val_loss: 2.4571 - val_acc: 0.2004 - val_categorical_crossentropy: 2.4571\n",
      "Epoch 17/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 2.1328 - acc: 0.2428 - categorical_crossentropy: 2.1328 - val_loss: 2.4443 - val_acc: 0.1784 - val_categorical_crossentropy: 2.4443\n",
      "Epoch 18/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 2.1075 - acc: 0.2479 - categorical_crossentropy: 2.1075 - val_loss: 2.4839 - val_acc: 0.1663 - val_categorical_crossentropy: 2.4839\n",
      "Epoch 19/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 2.0985 - acc: 0.2558 - categorical_crossentropy: 2.0985 - val_loss: 2.4566 - val_acc: 0.2024 - val_categorical_crossentropy: 2.4566\n",
      "Epoch 20/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 2.0788 - acc: 0.2577 - categorical_crossentropy: 2.0788 - val_loss: 2.4812 - val_acc: 0.1884 - val_categorical_crossentropy: 2.4812\n",
      "Epoch 21/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 2.0622 - acc: 0.2628 - categorical_crossentropy: 2.0622 - val_loss: 2.4659 - val_acc: 0.2064 - val_categorical_crossentropy: 2.4659\n",
      "Epoch 22/500\n",
      "8999/8999 [==============================] - 1s 143us/sample - loss: 2.0435 - acc: 0.2694 - categorical_crossentropy: 2.0435 - val_loss: 2.5020 - val_acc: 0.1884 - val_categorical_crossentropy: 2.5020\n",
      "Epoch 23/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 2.0285 - acc: 0.2770 - categorical_crossentropy: 2.0285 - val_loss: 2.4909 - val_acc: 0.1804 - val_categorical_crossentropy: 2.4909\n",
      "Epoch 24/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 2.0160 - acc: 0.2794 - categorical_crossentropy: 2.0160 - val_loss: 2.5294 - val_acc: 0.1884 - val_categorical_crossentropy: 2.5294\n",
      "Epoch 25/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 2.0055 - acc: 0.2783 - categorical_crossentropy: 2.0055 - val_loss: 2.5460 - val_acc: 0.1723 - val_categorical_crossentropy: 2.5460\n",
      "Epoch 26/500\n",
      "8999/8999 [==============================] - 1s 140us/sample - loss: 1.9888 - acc: 0.2900 - categorical_crossentropy: 1.9888 - val_loss: 2.5336 - val_acc: 0.2124 - val_categorical_crossentropy: 2.5336\n",
      "Epoch 27/500\n",
      "8999/8999 [==============================] - 2s 167us/sample - loss: 1.9747 - acc: 0.2927 - categorical_crossentropy: 1.9747 - val_loss: 2.5753 - val_acc: 0.1784 - val_categorical_crossentropy: 2.5753\n",
      "Epoch 28/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.9688 - acc: 0.2914 - categorical_crossentropy: 1.9688 - val_loss: 2.5585 - val_acc: 0.1904 - val_categorical_crossentropy: 2.5585\n",
      "Epoch 29/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.9513 - acc: 0.2994 - categorical_crossentropy: 1.9513 - val_loss: 2.5451 - val_acc: 0.2004 - val_categorical_crossentropy: 2.5451\n",
      "Epoch 30/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.9457 - acc: 0.3063 - categorical_crossentropy: 1.9457 - val_loss: 2.6111 - val_acc: 0.1864 - val_categorical_crossentropy: 2.6111\n",
      "Epoch 31/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.9297 - acc: 0.3077 - categorical_crossentropy: 1.9297 - val_loss: 2.5470 - val_acc: 0.2124 - val_categorical_crossentropy: 2.5470\n",
      "Epoch 32/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.9132 - acc: 0.3205 - categorical_crossentropy: 1.9132 - val_loss: 2.5722 - val_acc: 0.1884 - val_categorical_crossentropy: 2.5722\n",
      "Epoch 33/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.9149 - acc: 0.3180 - categorical_crossentropy: 1.9149 - val_loss: 2.5942 - val_acc: 0.2004 - val_categorical_crossentropy: 2.5942\n",
      "Epoch 34/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.9052 - acc: 0.3157 - categorical_crossentropy: 1.9052 - val_loss: 2.6271 - val_acc: 0.2124 - val_categorical_crossentropy: 2.6271\n",
      "Epoch 35/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.8895 - acc: 0.3244 - categorical_crossentropy: 1.8895 - val_loss: 2.5835 - val_acc: 0.1884 - val_categorical_crossentropy: 2.5835\n",
      "Epoch 36/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.8776 - acc: 0.3369 - categorical_crossentropy: 1.8776 - val_loss: 2.5597 - val_acc: 0.2104 - val_categorical_crossentropy: 2.5597\n",
      "Epoch 37/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.8657 - acc: 0.3379 - categorical_crossentropy: 1.8657 - val_loss: 2.5967 - val_acc: 0.2104 - val_categorical_crossentropy: 2.5967\n",
      "Epoch 38/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.8630 - acc: 0.3359 - categorical_crossentropy: 1.8630 - val_loss: 2.5769 - val_acc: 0.1864 - val_categorical_crossentropy: 2.5769\n",
      "Epoch 39/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.8509 - acc: 0.3403 - categorical_crossentropy: 1.8509 - val_loss: 2.5884 - val_acc: 0.1984 - val_categorical_crossentropy: 2.5884\n",
      "Epoch 40/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.8463 - acc: 0.3433 - categorical_crossentropy: 1.8463 - val_loss: 2.6126 - val_acc: 0.1904 - val_categorical_crossentropy: 2.6126\n",
      "Epoch 41/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.8348 - acc: 0.3499 - categorical_crossentropy: 1.8348 - val_loss: 2.6809 - val_acc: 0.1964 - val_categorical_crossentropy: 2.6809\n",
      "Epoch 42/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.8297 - acc: 0.3493 - categorical_crossentropy: 1.8297 - val_loss: 2.6608 - val_acc: 0.2084 - val_categorical_crossentropy: 2.6608\n",
      "Epoch 43/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.8310 - acc: 0.3514 - categorical_crossentropy: 1.8310 - val_loss: 2.6475 - val_acc: 0.2044 - val_categorical_crossentropy: 2.6475\n",
      "Epoch 44/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.8169 - acc: 0.3549 - categorical_crossentropy: 1.8169 - val_loss: 2.6730 - val_acc: 0.2004 - val_categorical_crossentropy: 2.6730\n",
      "Epoch 45/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.8082 - acc: 0.3520 - categorical_crossentropy: 1.8082 - val_loss: 2.6813 - val_acc: 0.2004 - val_categorical_crossentropy: 2.6813\n",
      "Epoch 46/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.8203 - acc: 0.3547 - categorical_crossentropy: 1.8203 - val_loss: 2.6971 - val_acc: 0.2004 - val_categorical_crossentropy: 2.6971\n",
      "Epoch 47/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.7932 - acc: 0.3585 - categorical_crossentropy: 1.7932 - val_loss: 2.7313 - val_acc: 0.2044 - val_categorical_crossentropy: 2.7313\n",
      "Epoch 48/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.7939 - acc: 0.3606 - categorical_crossentropy: 1.7939 - val_loss: 2.6776 - val_acc: 0.2024 - val_categorical_crossentropy: 2.6776\n",
      "Epoch 49/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.7854 - acc: 0.3695 - categorical_crossentropy: 1.7854 - val_loss: 2.7390 - val_acc: 0.2004 - val_categorical_crossentropy: 2.7390\n",
      "Epoch 50/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.7719 - acc: 0.3703 - categorical_crossentropy: 1.7719 - val_loss: 2.6817 - val_acc: 0.2144 - val_categorical_crossentropy: 2.6817\n",
      "Epoch 51/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.7710 - acc: 0.3688 - categorical_crossentropy: 1.7710 - val_loss: 2.6679 - val_acc: 0.2164 - val_categorical_crossentropy: 2.6679\n",
      "Epoch 52/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.7695 - acc: 0.3638 - categorical_crossentropy: 1.7695 - val_loss: 2.6589 - val_acc: 0.2064 - val_categorical_crossentropy: 2.6589\n",
      "Epoch 53/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.7623 - acc: 0.3748 - categorical_crossentropy: 1.7623 - val_loss: 2.8118 - val_acc: 0.1824 - val_categorical_crossentropy: 2.8118\n",
      "Epoch 54/500\n",
      "8999/8999 [==============================] - 1s 141us/sample - loss: 1.7654 - acc: 0.3704 - categorical_crossentropy: 1.7654 - val_loss: 2.7235 - val_acc: 0.1864 - val_categorical_crossentropy: 2.7235\n",
      "Epoch 55/500\n",
      "8999/8999 [==============================] - 1s 148us/sample - loss: 1.7491 - acc: 0.3746 - categorical_crossentropy: 1.7491 - val_loss: 2.7401 - val_acc: 0.2184 - val_categorical_crossentropy: 2.7401\n",
      "Epoch 56/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.7409 - acc: 0.3780 - categorical_crossentropy: 1.7409 - val_loss: 2.8708 - val_acc: 0.1764 - val_categorical_crossentropy: 2.8708\n",
      "Epoch 57/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.7438 - acc: 0.3800 - categorical_crossentropy: 1.7438 - val_loss: 2.7880 - val_acc: 0.2425 - val_categorical_crossentropy: 2.7880\n",
      "Epoch 58/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.7461 - acc: 0.3752 - categorical_crossentropy: 1.7461 - val_loss: 2.7706 - val_acc: 0.1984 - val_categorical_crossentropy: 2.7706\n",
      "Epoch 59/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.7267 - acc: 0.3826 - categorical_crossentropy: 1.7267 - val_loss: 2.8122 - val_acc: 0.1984 - val_categorical_crossentropy: 2.8122\n",
      "Epoch 60/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.7276 - acc: 0.3845 - categorical_crossentropy: 1.7276 - val_loss: 2.8765 - val_acc: 0.2004 - val_categorical_crossentropy: 2.8765\n",
      "Epoch 61/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.7219 - acc: 0.3862 - categorical_crossentropy: 1.7219 - val_loss: 2.7402 - val_acc: 0.2064 - val_categorical_crossentropy: 2.7402\n",
      "Epoch 62/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.7300 - acc: 0.3827 - categorical_crossentropy: 1.7300 - val_loss: 2.7403 - val_acc: 0.2044 - val_categorical_crossentropy: 2.7403\n",
      "Epoch 63/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.7071 - acc: 0.3924 - categorical_crossentropy: 1.7071 - val_loss: 2.7736 - val_acc: 0.2044 - val_categorical_crossentropy: 2.7736\n",
      "Epoch 64/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.7241 - acc: 0.3819 - categorical_crossentropy: 1.7241 - val_loss: 2.7234 - val_acc: 0.2204 - val_categorical_crossentropy: 2.7234\n",
      "Epoch 65/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.6925 - acc: 0.3928 - categorical_crossentropy: 1.6925 - val_loss: 2.7046 - val_acc: 0.2285 - val_categorical_crossentropy: 2.7046\n",
      "Epoch 66/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.6984 - acc: 0.3895 - categorical_crossentropy: 1.6984 - val_loss: 2.8752 - val_acc: 0.2164 - val_categorical_crossentropy: 2.8752\n",
      "Epoch 67/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.7036 - acc: 0.3903 - categorical_crossentropy: 1.7036 - val_loss: 2.7547 - val_acc: 0.2224 - val_categorical_crossentropy: 2.7547\n",
      "Epoch 68/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.6942 - acc: 0.3956 - categorical_crossentropy: 1.6942 - val_loss: 2.8651 - val_acc: 0.2024 - val_categorical_crossentropy: 2.8651\n",
      "Epoch 69/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.6823 - acc: 0.3958 - categorical_crossentropy: 1.6823 - val_loss: 2.7816 - val_acc: 0.1884 - val_categorical_crossentropy: 2.7816\n",
      "Epoch 70/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.6855 - acc: 0.3959 - categorical_crossentropy: 1.6855 - val_loss: 2.7952 - val_acc: 0.2064 - val_categorical_crossentropy: 2.7952\n",
      "Epoch 71/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.7013 - acc: 0.3945 - categorical_crossentropy: 1.7013 - val_loss: 2.7992 - val_acc: 0.2244 - val_categorical_crossentropy: 2.7992\n",
      "Epoch 72/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.6738 - acc: 0.4008 - categorical_crossentropy: 1.6738 - val_loss: 2.7381 - val_acc: 0.1944 - val_categorical_crossentropy: 2.7381\n",
      "Epoch 73/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.6701 - acc: 0.3972 - categorical_crossentropy: 1.6701 - val_loss: 2.7854 - val_acc: 0.2144 - val_categorical_crossentropy: 2.7854\n",
      "Epoch 74/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.6620 - acc: 0.4017 - categorical_crossentropy: 1.6620 - val_loss: 2.8189 - val_acc: 0.2164 - val_categorical_crossentropy: 2.8189\n",
      "Epoch 75/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.6643 - acc: 0.4012 - categorical_crossentropy: 1.6643 - val_loss: 2.9644 - val_acc: 0.2044 - val_categorical_crossentropy: 2.9644\n",
      "Epoch 76/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.6553 - acc: 0.4085 - categorical_crossentropy: 1.6553 - val_loss: 2.8515 - val_acc: 0.1944 - val_categorical_crossentropy: 2.8515\n",
      "Epoch 77/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.6684 - acc: 0.3997 - categorical_crossentropy: 1.6684 - val_loss: 2.8651 - val_acc: 0.1924 - val_categorical_crossentropy: 2.8651\n",
      "Epoch 78/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.6575 - acc: 0.4035 - categorical_crossentropy: 1.6575 - val_loss: 2.9142 - val_acc: 0.2004 - val_categorical_crossentropy: 2.9142\n",
      "Epoch 79/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.6589 - acc: 0.4059 - categorical_crossentropy: 1.6589 - val_loss: 2.8386 - val_acc: 0.2184 - val_categorical_crossentropy: 2.8386\n",
      "Epoch 80/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.6329 - acc: 0.4146 - categorical_crossentropy: 1.6329 - val_loss: 2.9566 - val_acc: 0.2024 - val_categorical_crossentropy: 2.9566\n",
      "Epoch 81/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.6125 - acc: 0.4206 - categorical_crossentropy: 1.6125 - val_loss: 2.9539 - val_acc: 0.2004 - val_categorical_crossentropy: 2.9539\n",
      "Epoch 82/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.6505 - acc: 0.4090 - categorical_crossentropy: 1.6505 - val_loss: 2.9568 - val_acc: 0.2124 - val_categorical_crossentropy: 2.9568\n",
      "Epoch 83/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.6285 - acc: 0.4165 - categorical_crossentropy: 1.6285 - val_loss: 2.9372 - val_acc: 0.1844 - val_categorical_crossentropy: 2.9372\n",
      "Epoch 84/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.6297 - acc: 0.4140 - categorical_crossentropy: 1.6297 - val_loss: 2.9618 - val_acc: 0.2184 - val_categorical_crossentropy: 2.9618\n",
      "Epoch 85/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.6133 - acc: 0.4163 - categorical_crossentropy: 1.6133 - val_loss: 2.9770 - val_acc: 0.2164 - val_categorical_crossentropy: 2.9770\n",
      "Epoch 86/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.6170 - acc: 0.4174 - categorical_crossentropy: 1.6170 - val_loss: 2.9815 - val_acc: 0.1944 - val_categorical_crossentropy: 2.9815\n",
      "Epoch 87/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.6165 - acc: 0.4177 - categorical_crossentropy: 1.6165 - val_loss: 2.9502 - val_acc: 0.1984 - val_categorical_crossentropy: 2.9502\n",
      "Epoch 88/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.6007 - acc: 0.4287 - categorical_crossentropy: 1.6007 - val_loss: 2.9538 - val_acc: 0.2104 - val_categorical_crossentropy: 2.9538\n",
      "Epoch 89/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.6089 - acc: 0.4226 - categorical_crossentropy: 1.6089 - val_loss: 3.0043 - val_acc: 0.2084 - val_categorical_crossentropy: 3.0043\n",
      "Epoch 90/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.6170 - acc: 0.4164 - categorical_crossentropy: 1.6170 - val_loss: 2.9932 - val_acc: 0.1964 - val_categorical_crossentropy: 2.9932\n",
      "Epoch 91/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.5873 - acc: 0.4310 - categorical_crossentropy: 1.5873 - val_loss: 2.9870 - val_acc: 0.1984 - val_categorical_crossentropy: 2.9870\n",
      "Epoch 92/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.5849 - acc: 0.4317 - categorical_crossentropy: 1.5849 - val_loss: 2.9362 - val_acc: 0.2104 - val_categorical_crossentropy: 2.9362\n",
      "Epoch 93/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5954 - acc: 0.4264 - categorical_crossentropy: 1.5954 - val_loss: 3.0105 - val_acc: 0.2104 - val_categorical_crossentropy: 3.0105\n",
      "Epoch 94/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5714 - acc: 0.4336 - categorical_crossentropy: 1.5714 - val_loss: 3.0895 - val_acc: 0.1904 - val_categorical_crossentropy: 3.0895\n",
      "Epoch 95/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.6072 - acc: 0.4246 - categorical_crossentropy: 1.6072 - val_loss: 2.9638 - val_acc: 0.1964 - val_categorical_crossentropy: 2.9638\n",
      "Epoch 96/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5837 - acc: 0.4326 - categorical_crossentropy: 1.5837 - val_loss: 3.0547 - val_acc: 0.2144 - val_categorical_crossentropy: 3.0547\n",
      "Epoch 97/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.5839 - acc: 0.4298 - categorical_crossentropy: 1.5839 - val_loss: 3.0692 - val_acc: 0.2004 - val_categorical_crossentropy: 3.0692\n",
      "Epoch 98/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5757 - acc: 0.4364 - categorical_crossentropy: 1.5757 - val_loss: 3.1648 - val_acc: 0.2024 - val_categorical_crossentropy: 3.1648\n",
      "Epoch 99/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5595 - acc: 0.4377 - categorical_crossentropy: 1.5595 - val_loss: 3.0433 - val_acc: 0.2104 - val_categorical_crossentropy: 3.0433\n",
      "Epoch 100/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5710 - acc: 0.4409 - categorical_crossentropy: 1.5710 - val_loss: 3.1705 - val_acc: 0.1864 - val_categorical_crossentropy: 3.1705\n",
      "Epoch 101/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5681 - acc: 0.4428 - categorical_crossentropy: 1.5681 - val_loss: 3.0299 - val_acc: 0.1944 - val_categorical_crossentropy: 3.0299\n",
      "Epoch 102/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.5449 - acc: 0.4447 - categorical_crossentropy: 1.5449 - val_loss: 3.0854 - val_acc: 0.2144 - val_categorical_crossentropy: 3.0854\n",
      "Epoch 103/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5972 - acc: 0.4336 - categorical_crossentropy: 1.5972 - val_loss: 3.0579 - val_acc: 0.1864 - val_categorical_crossentropy: 3.0579\n",
      "Epoch 104/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5594 - acc: 0.4383 - categorical_crossentropy: 1.5594 - val_loss: 3.2103 - val_acc: 0.1984 - val_categorical_crossentropy: 3.2103\n",
      "Epoch 105/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5473 - acc: 0.4443 - categorical_crossentropy: 1.5473 - val_loss: 3.0965 - val_acc: 0.1944 - val_categorical_crossentropy: 3.0965\n",
      "Epoch 106/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5310 - acc: 0.4522 - categorical_crossentropy: 1.5310 - val_loss: 3.1010 - val_acc: 0.1984 - val_categorical_crossentropy: 3.1010\n",
      "Epoch 107/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5488 - acc: 0.4402 - categorical_crossentropy: 1.5488 - val_loss: 3.1941 - val_acc: 0.2104 - val_categorical_crossentropy: 3.1941\n",
      "Epoch 108/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5463 - acc: 0.4531 - categorical_crossentropy: 1.5463 - val_loss: 3.0494 - val_acc: 0.2144 - val_categorical_crossentropy: 3.0494\n",
      "Epoch 109/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5404 - acc: 0.4463 - categorical_crossentropy: 1.5404 - val_loss: 3.0901 - val_acc: 0.1924 - val_categorical_crossentropy: 3.0901\n",
      "Epoch 110/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5574 - acc: 0.4426 - categorical_crossentropy: 1.5574 - val_loss: 3.0516 - val_acc: 0.1844 - val_categorical_crossentropy: 3.0516\n",
      "Epoch 111/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5469 - acc: 0.4462 - categorical_crossentropy: 1.5469 - val_loss: 3.1852 - val_acc: 0.1723 - val_categorical_crossentropy: 3.1852\n",
      "Epoch 112/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5079 - acc: 0.4626 - categorical_crossentropy: 1.5079 - val_loss: 3.1762 - val_acc: 0.1904 - val_categorical_crossentropy: 3.1762\n",
      "Epoch 113/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5169 - acc: 0.4598 - categorical_crossentropy: 1.5169 - val_loss: 3.2464 - val_acc: 0.1984 - val_categorical_crossentropy: 3.2464\n",
      "Epoch 114/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5087 - acc: 0.4605 - categorical_crossentropy: 1.5087 - val_loss: 3.1852 - val_acc: 0.2024 - val_categorical_crossentropy: 3.1852\n",
      "Epoch 115/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5170 - acc: 0.4609 - categorical_crossentropy: 1.5170 - val_loss: 3.2839 - val_acc: 0.1944 - val_categorical_crossentropy: 3.2839\n",
      "Epoch 116/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5170 - acc: 0.4562 - categorical_crossentropy: 1.5170 - val_loss: 3.2369 - val_acc: 0.1844 - val_categorical_crossentropy: 3.2369\n",
      "Epoch 117/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5150 - acc: 0.4561 - categorical_crossentropy: 1.5150 - val_loss: 3.2024 - val_acc: 0.2024 - val_categorical_crossentropy: 3.2024\n",
      "Epoch 118/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5105 - acc: 0.4624 - categorical_crossentropy: 1.5105 - val_loss: 3.2774 - val_acc: 0.1844 - val_categorical_crossentropy: 3.2774\n",
      "Epoch 119/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5086 - acc: 0.4592 - categorical_crossentropy: 1.5086 - val_loss: 3.3093 - val_acc: 0.1864 - val_categorical_crossentropy: 3.3093\n",
      "Epoch 120/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5393 - acc: 0.4499 - categorical_crossentropy: 1.5393 - val_loss: 3.0780 - val_acc: 0.2104 - val_categorical_crossentropy: 3.0780\n",
      "Epoch 121/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5066 - acc: 0.4599 - categorical_crossentropy: 1.5066 - val_loss: 3.2760 - val_acc: 0.2024 - val_categorical_crossentropy: 3.2760\n",
      "Epoch 122/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.4955 - acc: 0.4611 - categorical_crossentropy: 1.4955 - val_loss: 3.3175 - val_acc: 0.1924 - val_categorical_crossentropy: 3.3175\n",
      "Epoch 123/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4821 - acc: 0.4708 - categorical_crossentropy: 1.4821 - val_loss: 3.1706 - val_acc: 0.1944 - val_categorical_crossentropy: 3.1706\n",
      "Epoch 124/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4868 - acc: 0.4607 - categorical_crossentropy: 1.4868 - val_loss: 3.2577 - val_acc: 0.2064 - val_categorical_crossentropy: 3.2577\n",
      "Epoch 125/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.5075 - acc: 0.4613 - categorical_crossentropy: 1.5075 - val_loss: 3.1000 - val_acc: 0.1944 - val_categorical_crossentropy: 3.1000\n",
      "Epoch 126/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4928 - acc: 0.4692 - categorical_crossentropy: 1.4928 - val_loss: 3.1926 - val_acc: 0.2104 - val_categorical_crossentropy: 3.1926\n",
      "Epoch 127/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.4812 - acc: 0.4716 - categorical_crossentropy: 1.4812 - val_loss: 3.2371 - val_acc: 0.1964 - val_categorical_crossentropy: 3.2371\n",
      "Epoch 128/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4631 - acc: 0.4757 - categorical_crossentropy: 1.4632 - val_loss: 3.1967 - val_acc: 0.2104 - val_categorical_crossentropy: 3.1967\n",
      "Epoch 129/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.5079 - acc: 0.4614 - categorical_crossentropy: 1.5079 - val_loss: 3.1861 - val_acc: 0.1904 - val_categorical_crossentropy: 3.1861\n",
      "Epoch 130/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4822 - acc: 0.4722 - categorical_crossentropy: 1.4822 - val_loss: 3.3346 - val_acc: 0.1824 - val_categorical_crossentropy: 3.3346\n",
      "Epoch 131/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.4886 - acc: 0.4628 - categorical_crossentropy: 1.4886 - val_loss: 3.2736 - val_acc: 0.1723 - val_categorical_crossentropy: 3.2736\n",
      "Epoch 132/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4653 - acc: 0.4717 - categorical_crossentropy: 1.4653 - val_loss: 3.2381 - val_acc: 0.1904 - val_categorical_crossentropy: 3.2381\n",
      "Epoch 133/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.4702 - acc: 0.4696 - categorical_crossentropy: 1.4702 - val_loss: 3.2720 - val_acc: 0.2004 - val_categorical_crossentropy: 3.2720\n",
      "Epoch 134/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4665 - acc: 0.4735 - categorical_crossentropy: 1.4665 - val_loss: 3.2615 - val_acc: 0.1984 - val_categorical_crossentropy: 3.2615\n",
      "Epoch 135/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.4562 - acc: 0.4796 - categorical_crossentropy: 1.4562 - val_loss: 3.2267 - val_acc: 0.1824 - val_categorical_crossentropy: 3.2267\n",
      "Epoch 136/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.4955 - acc: 0.4719 - categorical_crossentropy: 1.4955 - val_loss: 3.1789 - val_acc: 0.2184 - val_categorical_crossentropy: 3.1789\n",
      "Epoch 137/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4755 - acc: 0.4696 - categorical_crossentropy: 1.4755 - val_loss: 3.1963 - val_acc: 0.1924 - val_categorical_crossentropy: 3.1963\n",
      "Epoch 138/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.4671 - acc: 0.4733 - categorical_crossentropy: 1.4671 - val_loss: 3.2220 - val_acc: 0.1844 - val_categorical_crossentropy: 3.2220\n",
      "Epoch 139/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.4606 - acc: 0.4816 - categorical_crossentropy: 1.4606 - val_loss: 3.2931 - val_acc: 0.2064 - val_categorical_crossentropy: 3.2931\n",
      "Epoch 140/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.4559 - acc: 0.4815 - categorical_crossentropy: 1.4559 - val_loss: 3.2635 - val_acc: 0.1944 - val_categorical_crossentropy: 3.2635\n",
      "Epoch 141/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.4406 - acc: 0.4859 - categorical_crossentropy: 1.4406 - val_loss: 3.3831 - val_acc: 0.1924 - val_categorical_crossentropy: 3.3831\n",
      "Epoch 142/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.4531 - acc: 0.4791 - categorical_crossentropy: 1.4531 - val_loss: 3.3389 - val_acc: 0.1964 - val_categorical_crossentropy: 3.3389\n",
      "Epoch 143/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4598 - acc: 0.4781 - categorical_crossentropy: 1.4598 - val_loss: 3.2645 - val_acc: 0.1944 - val_categorical_crossentropy: 3.2645\n",
      "Epoch 144/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4466 - acc: 0.4813 - categorical_crossentropy: 1.4466 - val_loss: 3.3302 - val_acc: 0.2004 - val_categorical_crossentropy: 3.3302\n",
      "Epoch 145/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.4541 - acc: 0.4853 - categorical_crossentropy: 1.4541 - val_loss: 3.2971 - val_acc: 0.2164 - val_categorical_crossentropy: 3.2971\n",
      "Epoch 146/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4631 - acc: 0.4823 - categorical_crossentropy: 1.4631 - val_loss: 3.3462 - val_acc: 0.1864 - val_categorical_crossentropy: 3.3462\n",
      "Epoch 147/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4320 - acc: 0.4859 - categorical_crossentropy: 1.4320 - val_loss: 3.2367 - val_acc: 0.1964 - val_categorical_crossentropy: 3.2367\n",
      "Epoch 148/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4416 - acc: 0.4865 - categorical_crossentropy: 1.4416 - val_loss: 3.3362 - val_acc: 0.2004 - val_categorical_crossentropy: 3.3362\n",
      "Epoch 149/500\n",
      "8999/8999 [==============================] - 1s 145us/sample - loss: 1.4451 - acc: 0.4837 - categorical_crossentropy: 1.4451 - val_loss: 3.3395 - val_acc: 0.2004 - val_categorical_crossentropy: 3.3395\n",
      "Epoch 150/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4489 - acc: 0.4808 - categorical_crossentropy: 1.4489 - val_loss: 3.2641 - val_acc: 0.2064 - val_categorical_crossentropy: 3.2641\n",
      "Epoch 151/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.4396 - acc: 0.4859 - categorical_crossentropy: 1.4396 - val_loss: 3.3701 - val_acc: 0.2004 - val_categorical_crossentropy: 3.3701\n",
      "Epoch 152/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.4390 - acc: 0.4839 - categorical_crossentropy: 1.4390 - val_loss: 3.3435 - val_acc: 0.2084 - val_categorical_crossentropy: 3.3435\n",
      "Epoch 153/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.4397 - acc: 0.4879 - categorical_crossentropy: 1.4397 - val_loss: 3.2836 - val_acc: 0.1964 - val_categorical_crossentropy: 3.2836\n",
      "Epoch 154/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4289 - acc: 0.4868 - categorical_crossentropy: 1.4289 - val_loss: 3.3171 - val_acc: 0.2044 - val_categorical_crossentropy: 3.3171\n",
      "Epoch 155/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.4312 - acc: 0.4906 - categorical_crossentropy: 1.4312 - val_loss: 3.3394 - val_acc: 0.2244 - val_categorical_crossentropy: 3.3394\n",
      "Epoch 156/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4189 - acc: 0.4893 - categorical_crossentropy: 1.4189 - val_loss: 3.4270 - val_acc: 0.2044 - val_categorical_crossentropy: 3.4270\n",
      "Epoch 157/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4138 - acc: 0.4998 - categorical_crossentropy: 1.4138 - val_loss: 3.4393 - val_acc: 0.2104 - val_categorical_crossentropy: 3.4393\n",
      "Epoch 158/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4385 - acc: 0.4875 - categorical_crossentropy: 1.4385 - val_loss: 3.3475 - val_acc: 0.2144 - val_categorical_crossentropy: 3.3475\n",
      "Epoch 159/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4434 - acc: 0.4839 - categorical_crossentropy: 1.4434 - val_loss: 3.2689 - val_acc: 0.2124 - val_categorical_crossentropy: 3.2689\n",
      "Epoch 160/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4135 - acc: 0.4928 - categorical_crossentropy: 1.4135 - val_loss: 3.3298 - val_acc: 0.2184 - val_categorical_crossentropy: 3.3298\n",
      "Epoch 161/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.4232 - acc: 0.4922 - categorical_crossentropy: 1.4232 - val_loss: 3.2853 - val_acc: 0.1984 - val_categorical_crossentropy: 3.2853\n",
      "Epoch 162/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3859 - acc: 0.5095 - categorical_crossentropy: 1.3859 - val_loss: 3.3158 - val_acc: 0.2144 - val_categorical_crossentropy: 3.3158\n",
      "Epoch 163/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4272 - acc: 0.4885 - categorical_crossentropy: 1.4272 - val_loss: 3.3572 - val_acc: 0.2004 - val_categorical_crossentropy: 3.3572\n",
      "Epoch 164/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4114 - acc: 0.5014 - categorical_crossentropy: 1.4114 - val_loss: 3.3099 - val_acc: 0.2124 - val_categorical_crossentropy: 3.3099\n",
      "Epoch 165/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4103 - acc: 0.4966 - categorical_crossentropy: 1.4103 - val_loss: 3.3569 - val_acc: 0.2044 - val_categorical_crossentropy: 3.3569\n",
      "Epoch 166/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3928 - acc: 0.5012 - categorical_crossentropy: 1.3928 - val_loss: 3.4576 - val_acc: 0.2064 - val_categorical_crossentropy: 3.4576\n",
      "Epoch 167/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4051 - acc: 0.4983 - categorical_crossentropy: 1.4051 - val_loss: 3.4249 - val_acc: 0.1964 - val_categorical_crossentropy: 3.4249\n",
      "Epoch 168/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4203 - acc: 0.4989 - categorical_crossentropy: 1.4203 - val_loss: 3.3669 - val_acc: 0.2144 - val_categorical_crossentropy: 3.3669\n",
      "Epoch 169/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3995 - acc: 0.4965 - categorical_crossentropy: 1.3995 - val_loss: 3.5822 - val_acc: 0.1904 - val_categorical_crossentropy: 3.5822\n",
      "Epoch 170/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.4027 - acc: 0.4998 - categorical_crossentropy: 1.4027 - val_loss: 3.4855 - val_acc: 0.2104 - val_categorical_crossentropy: 3.4855\n",
      "Epoch 171/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3956 - acc: 0.4983 - categorical_crossentropy: 1.3956 - val_loss: 3.4420 - val_acc: 0.2184 - val_categorical_crossentropy: 3.4420\n",
      "Epoch 172/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4100 - acc: 0.5006 - categorical_crossentropy: 1.4100 - val_loss: 3.4584 - val_acc: 0.2285 - val_categorical_crossentropy: 3.4584\n",
      "Epoch 173/500\n",
      "8999/8999 [==============================] - 1s 133us/sample - loss: 1.3882 - acc: 0.5103 - categorical_crossentropy: 1.3882 - val_loss: 3.3163 - val_acc: 0.2124 - val_categorical_crossentropy: 3.3163\n",
      "Epoch 174/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3963 - acc: 0.5024 - categorical_crossentropy: 1.3963 - val_loss: 3.4739 - val_acc: 0.2024 - val_categorical_crossentropy: 3.4739\n",
      "Epoch 175/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.4093 - acc: 0.5003 - categorical_crossentropy: 1.4093 - val_loss: 3.3663 - val_acc: 0.2325 - val_categorical_crossentropy: 3.3663\n",
      "Epoch 176/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.4011 - acc: 0.4993 - categorical_crossentropy: 1.4011 - val_loss: 3.5039 - val_acc: 0.2004 - val_categorical_crossentropy: 3.5039\n",
      "Epoch 177/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3864 - acc: 0.5014 - categorical_crossentropy: 1.3864 - val_loss: 3.5003 - val_acc: 0.2004 - val_categorical_crossentropy: 3.5003\n",
      "Epoch 178/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3625 - acc: 0.5156 - categorical_crossentropy: 1.3625 - val_loss: 3.5573 - val_acc: 0.2164 - val_categorical_crossentropy: 3.5573\n",
      "Epoch 179/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3899 - acc: 0.5074 - categorical_crossentropy: 1.3899 - val_loss: 3.4321 - val_acc: 0.2024 - val_categorical_crossentropy: 3.4321\n",
      "Epoch 180/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3791 - acc: 0.5058 - categorical_crossentropy: 1.3791 - val_loss: 3.5229 - val_acc: 0.2305 - val_categorical_crossentropy: 3.5229\n",
      "Epoch 181/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3770 - acc: 0.5061 - categorical_crossentropy: 1.3770 - val_loss: 3.4408 - val_acc: 0.2064 - val_categorical_crossentropy: 3.4408\n",
      "Epoch 182/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.4170 - acc: 0.5015 - categorical_crossentropy: 1.4170 - val_loss: 3.4031 - val_acc: 0.1984 - val_categorical_crossentropy: 3.4031\n",
      "Epoch 183/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3921 - acc: 0.5055 - categorical_crossentropy: 1.3921 - val_loss: 3.4967 - val_acc: 0.2004 - val_categorical_crossentropy: 3.4967\n",
      "Epoch 184/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3661 - acc: 0.5026 - categorical_crossentropy: 1.3661 - val_loss: 3.3899 - val_acc: 0.1924 - val_categorical_crossentropy: 3.3899\n",
      "Epoch 185/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3643 - acc: 0.5094 - categorical_crossentropy: 1.3643 - val_loss: 3.5024 - val_acc: 0.2104 - val_categorical_crossentropy: 3.5024\n",
      "Epoch 186/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3774 - acc: 0.5121 - categorical_crossentropy: 1.3774 - val_loss: 3.6113 - val_acc: 0.1784 - val_categorical_crossentropy: 3.6113\n",
      "Epoch 187/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3710 - acc: 0.5109 - categorical_crossentropy: 1.3710 - val_loss: 3.5597 - val_acc: 0.1904 - val_categorical_crossentropy: 3.5597\n",
      "Epoch 188/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3754 - acc: 0.5089 - categorical_crossentropy: 1.3754 - val_loss: 3.4888 - val_acc: 0.2164 - val_categorical_crossentropy: 3.4888\n",
      "Epoch 189/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3860 - acc: 0.5028 - categorical_crossentropy: 1.3860 - val_loss: 3.5797 - val_acc: 0.2084 - val_categorical_crossentropy: 3.5797\n",
      "Epoch 190/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3629 - acc: 0.5211 - categorical_crossentropy: 1.3629 - val_loss: 3.5132 - val_acc: 0.2064 - val_categorical_crossentropy: 3.5132\n",
      "Epoch 191/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3717 - acc: 0.5095 - categorical_crossentropy: 1.3717 - val_loss: 3.4925 - val_acc: 0.2244 - val_categorical_crossentropy: 3.4925\n",
      "Epoch 192/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3526 - acc: 0.5182 - categorical_crossentropy: 1.3526 - val_loss: 3.6067 - val_acc: 0.2024 - val_categorical_crossentropy: 3.6067\n",
      "Epoch 193/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3540 - acc: 0.5204 - categorical_crossentropy: 1.3540 - val_loss: 3.5660 - val_acc: 0.1984 - val_categorical_crossentropy: 3.5660\n",
      "Epoch 194/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3860 - acc: 0.5095 - categorical_crossentropy: 1.3860 - val_loss: 3.5122 - val_acc: 0.2004 - val_categorical_crossentropy: 3.5122\n",
      "Epoch 195/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3649 - acc: 0.5134 - categorical_crossentropy: 1.3649 - val_loss: 3.3972 - val_acc: 0.2004 - val_categorical_crossentropy: 3.3972\n",
      "Epoch 196/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3617 - acc: 0.5137 - categorical_crossentropy: 1.3617 - val_loss: 3.4590 - val_acc: 0.2024 - val_categorical_crossentropy: 3.4590\n",
      "Epoch 197/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3675 - acc: 0.5118 - categorical_crossentropy: 1.3675 - val_loss: 3.5416 - val_acc: 0.2124 - val_categorical_crossentropy: 3.5416\n",
      "Epoch 198/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3834 - acc: 0.5098 - categorical_crossentropy: 1.3834 - val_loss: 3.3277 - val_acc: 0.2064 - val_categorical_crossentropy: 3.3277\n",
      "Epoch 199/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.3767 - acc: 0.5134 - categorical_crossentropy: 1.3767 - val_loss: 3.4828 - val_acc: 0.1964 - val_categorical_crossentropy: 3.4828\n",
      "Epoch 200/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3471 - acc: 0.5206 - categorical_crossentropy: 1.3471 - val_loss: 3.5439 - val_acc: 0.2144 - val_categorical_crossentropy: 3.5439\n",
      "Epoch 201/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3595 - acc: 0.5098 - categorical_crossentropy: 1.3595 - val_loss: 3.4972 - val_acc: 0.2244 - val_categorical_crossentropy: 3.4972\n",
      "Epoch 202/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3630 - acc: 0.5151 - categorical_crossentropy: 1.3630 - val_loss: 3.4236 - val_acc: 0.2084 - val_categorical_crossentropy: 3.4236\n",
      "Epoch 203/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3365 - acc: 0.5222 - categorical_crossentropy: 1.3365 - val_loss: 3.6626 - val_acc: 0.2044 - val_categorical_crossentropy: 3.6626\n",
      "Epoch 204/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3546 - acc: 0.5138 - categorical_crossentropy: 1.3546 - val_loss: 3.6318 - val_acc: 0.2144 - val_categorical_crossentropy: 3.6318\n",
      "Epoch 205/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3455 - acc: 0.5227 - categorical_crossentropy: 1.3455 - val_loss: 3.5380 - val_acc: 0.2084 - val_categorical_crossentropy: 3.5380\n",
      "Epoch 206/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3559 - acc: 0.5195 - categorical_crossentropy: 1.3559 - val_loss: 3.4904 - val_acc: 0.2204 - val_categorical_crossentropy: 3.4904\n",
      "Epoch 207/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3453 - acc: 0.5246 - categorical_crossentropy: 1.3453 - val_loss: 3.4035 - val_acc: 0.2164 - val_categorical_crossentropy: 3.4035\n",
      "Epoch 208/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3500 - acc: 0.5192 - categorical_crossentropy: 1.3500 - val_loss: 3.6052 - val_acc: 0.2104 - val_categorical_crossentropy: 3.6052\n",
      "Epoch 209/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3709 - acc: 0.5082 - categorical_crossentropy: 1.3709 - val_loss: 3.4987 - val_acc: 0.2184 - val_categorical_crossentropy: 3.4987\n",
      "Epoch 210/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3518 - acc: 0.5164 - categorical_crossentropy: 1.3518 - val_loss: 3.3684 - val_acc: 0.2144 - val_categorical_crossentropy: 3.3684\n",
      "Epoch 211/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3743 - acc: 0.5111 - categorical_crossentropy: 1.3743 - val_loss: 3.4670 - val_acc: 0.2124 - val_categorical_crossentropy: 3.4670\n",
      "Epoch 212/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3529 - acc: 0.5185 - categorical_crossentropy: 1.3529 - val_loss: 3.4312 - val_acc: 0.2224 - val_categorical_crossentropy: 3.4312\n",
      "Epoch 213/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3206 - acc: 0.5252 - categorical_crossentropy: 1.3206 - val_loss: 3.5946 - val_acc: 0.2124 - val_categorical_crossentropy: 3.5946\n",
      "Epoch 214/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3296 - acc: 0.5201 - categorical_crossentropy: 1.3296 - val_loss: 3.5269 - val_acc: 0.2064 - val_categorical_crossentropy: 3.5269\n",
      "Epoch 215/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3297 - acc: 0.5272 - categorical_crossentropy: 1.3297 - val_loss: 3.6267 - val_acc: 0.2164 - val_categorical_crossentropy: 3.6267\n",
      "Epoch 216/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.3359 - acc: 0.5248 - categorical_crossentropy: 1.3359 - val_loss: 3.5533 - val_acc: 0.2184 - val_categorical_crossentropy: 3.5533\n",
      "Epoch 217/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3220 - acc: 0.5319 - categorical_crossentropy: 1.3220 - val_loss: 3.6586 - val_acc: 0.2204 - val_categorical_crossentropy: 3.6586\n",
      "Epoch 218/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3584 - acc: 0.5196 - categorical_crossentropy: 1.3584 - val_loss: 3.5095 - val_acc: 0.2144 - val_categorical_crossentropy: 3.5095\n",
      "Epoch 219/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3520 - acc: 0.5181 - categorical_crossentropy: 1.3520 - val_loss: 3.6580 - val_acc: 0.2044 - val_categorical_crossentropy: 3.6580\n",
      "Epoch 220/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3891 - acc: 0.5105 - categorical_crossentropy: 1.3891 - val_loss: 3.4830 - val_acc: 0.2104 - val_categorical_crossentropy: 3.4830\n",
      "Epoch 221/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.3318 - acc: 0.5244 - categorical_crossentropy: 1.3318 - val_loss: 3.6772 - val_acc: 0.2204 - val_categorical_crossentropy: 3.6772\n",
      "Epoch 222/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3337 - acc: 0.5234 - categorical_crossentropy: 1.3337 - val_loss: 3.5703 - val_acc: 0.2064 - val_categorical_crossentropy: 3.5703\n",
      "Epoch 223/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3296 - acc: 0.5254 - categorical_crossentropy: 1.3296 - val_loss: 3.6136 - val_acc: 0.1964 - val_categorical_crossentropy: 3.6136\n",
      "Epoch 224/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3343 - acc: 0.5245 - categorical_crossentropy: 1.3343 - val_loss: 3.6794 - val_acc: 0.2084 - val_categorical_crossentropy: 3.6794\n",
      "Epoch 225/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3171 - acc: 0.5282 - categorical_crossentropy: 1.3171 - val_loss: 3.6052 - val_acc: 0.2204 - val_categorical_crossentropy: 3.6052\n",
      "Epoch 226/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3166 - acc: 0.5338 - categorical_crossentropy: 1.3166 - val_loss: 3.7583 - val_acc: 0.2184 - val_categorical_crossentropy: 3.7583\n",
      "Epoch 227/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.3116 - acc: 0.5363 - categorical_crossentropy: 1.3116 - val_loss: 3.6284 - val_acc: 0.2104 - val_categorical_crossentropy: 3.6284\n",
      "Epoch 228/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3643 - acc: 0.5118 - categorical_crossentropy: 1.3643 - val_loss: 3.7635 - val_acc: 0.2064 - val_categorical_crossentropy: 3.7635\n",
      "Epoch 229/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3170 - acc: 0.5311 - categorical_crossentropy: 1.3170 - val_loss: 3.7415 - val_acc: 0.2204 - val_categorical_crossentropy: 3.7415\n",
      "Epoch 230/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3136 - acc: 0.5311 - categorical_crossentropy: 1.3136 - val_loss: 3.6276 - val_acc: 0.2164 - val_categorical_crossentropy: 3.6276\n",
      "Epoch 231/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3026 - acc: 0.5362 - categorical_crossentropy: 1.3026 - val_loss: 3.6911 - val_acc: 0.2164 - val_categorical_crossentropy: 3.6911\n",
      "Epoch 232/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2975 - acc: 0.5394 - categorical_crossentropy: 1.2975 - val_loss: 3.7781 - val_acc: 0.2104 - val_categorical_crossentropy: 3.7781\n",
      "Epoch 233/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3275 - acc: 0.5266 - categorical_crossentropy: 1.3275 - val_loss: 3.7545 - val_acc: 0.2044 - val_categorical_crossentropy: 3.7545\n",
      "Epoch 234/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3465 - acc: 0.5239 - categorical_crossentropy: 1.3465 - val_loss: 3.6036 - val_acc: 0.2104 - val_categorical_crossentropy: 3.6036\n",
      "Epoch 235/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3059 - acc: 0.5342 - categorical_crossentropy: 1.3059 - val_loss: 3.7198 - val_acc: 0.2164 - val_categorical_crossentropy: 3.7198\n",
      "Epoch 236/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.2854 - acc: 0.5426 - categorical_crossentropy: 1.2854 - val_loss: 3.6967 - val_acc: 0.2084 - val_categorical_crossentropy: 3.6967\n",
      "Epoch 237/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3295 - acc: 0.5331 - categorical_crossentropy: 1.3295 - val_loss: 3.5153 - val_acc: 0.2104 - val_categorical_crossentropy: 3.5153\n",
      "Epoch 238/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3098 - acc: 0.5318 - categorical_crossentropy: 1.3098 - val_loss: 3.7113 - val_acc: 0.2044 - val_categorical_crossentropy: 3.7113\n",
      "Epoch 239/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3026 - acc: 0.5368 - categorical_crossentropy: 1.3026 - val_loss: 3.8149 - val_acc: 0.1924 - val_categorical_crossentropy: 3.8149\n",
      "Epoch 240/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.3125 - acc: 0.5335 - categorical_crossentropy: 1.3125 - val_loss: 3.7579 - val_acc: 0.2144 - val_categorical_crossentropy: 3.7579\n",
      "Epoch 241/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3052 - acc: 0.5368 - categorical_crossentropy: 1.3052 - val_loss: 3.7894 - val_acc: 0.2084 - val_categorical_crossentropy: 3.7894\n",
      "Epoch 242/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2930 - acc: 0.5432 - categorical_crossentropy: 1.2930 - val_loss: 3.6927 - val_acc: 0.2004 - val_categorical_crossentropy: 3.6927\n",
      "Epoch 243/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3038 - acc: 0.5388 - categorical_crossentropy: 1.3038 - val_loss: 3.6745 - val_acc: 0.1924 - val_categorical_crossentropy: 3.6745\n",
      "Epoch 244/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3168 - acc: 0.5294 - categorical_crossentropy: 1.3168 - val_loss: 3.7915 - val_acc: 0.1984 - val_categorical_crossentropy: 3.7915\n",
      "Epoch 245/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3168 - acc: 0.5324 - categorical_crossentropy: 1.3168 - val_loss: 3.6720 - val_acc: 0.2204 - val_categorical_crossentropy: 3.6720\n",
      "Epoch 246/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3231 - acc: 0.5302 - categorical_crossentropy: 1.3231 - val_loss: 3.5758 - val_acc: 0.2104 - val_categorical_crossentropy: 3.5758\n",
      "Epoch 247/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2962 - acc: 0.5353 - categorical_crossentropy: 1.2962 - val_loss: 3.8107 - val_acc: 0.2004 - val_categorical_crossentropy: 3.8107\n",
      "Epoch 248/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2799 - acc: 0.5424 - categorical_crossentropy: 1.2799 - val_loss: 3.8557 - val_acc: 0.2385 - val_categorical_crossentropy: 3.8557\n",
      "Epoch 249/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3155 - acc: 0.5333 - categorical_crossentropy: 1.3155 - val_loss: 3.6308 - val_acc: 0.2124 - val_categorical_crossentropy: 3.6308\n",
      "Epoch 250/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2975 - acc: 0.5357 - categorical_crossentropy: 1.2975 - val_loss: 3.8501 - val_acc: 0.2064 - val_categorical_crossentropy: 3.8501\n",
      "Epoch 251/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2862 - acc: 0.5371 - categorical_crossentropy: 1.2862 - val_loss: 3.7919 - val_acc: 0.2104 - val_categorical_crossentropy: 3.7919\n",
      "Epoch 252/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2999 - acc: 0.5396 - categorical_crossentropy: 1.2999 - val_loss: 3.8724 - val_acc: 0.2084 - val_categorical_crossentropy: 3.8724\n",
      "Epoch 253/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3096 - acc: 0.5371 - categorical_crossentropy: 1.3096 - val_loss: 3.7290 - val_acc: 0.1984 - val_categorical_crossentropy: 3.7290\n",
      "Epoch 254/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2927 - acc: 0.5406 - categorical_crossentropy: 1.2927 - val_loss: 3.7527 - val_acc: 0.1944 - val_categorical_crossentropy: 3.7527\n",
      "Epoch 255/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2951 - acc: 0.5389 - categorical_crossentropy: 1.2951 - val_loss: 3.9274 - val_acc: 0.2124 - val_categorical_crossentropy: 3.9274\n",
      "Epoch 256/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2926 - acc: 0.5421 - categorical_crossentropy: 1.2926 - val_loss: 3.8300 - val_acc: 0.1984 - val_categorical_crossentropy: 3.8300\n",
      "Epoch 257/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2992 - acc: 0.5352 - categorical_crossentropy: 1.2992 - val_loss: 3.8631 - val_acc: 0.1864 - val_categorical_crossentropy: 3.8631\n",
      "Epoch 258/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2751 - acc: 0.5471 - categorical_crossentropy: 1.2751 - val_loss: 3.7649 - val_acc: 0.2124 - val_categorical_crossentropy: 3.7649\n",
      "Epoch 259/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2820 - acc: 0.5463 - categorical_crossentropy: 1.2820 - val_loss: 3.8935 - val_acc: 0.2004 - val_categorical_crossentropy: 3.8935\n",
      "Epoch 260/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3111 - acc: 0.5307 - categorical_crossentropy: 1.3111 - val_loss: 3.6120 - val_acc: 0.2104 - val_categorical_crossentropy: 3.6120\n",
      "Epoch 261/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2868 - acc: 0.5418 - categorical_crossentropy: 1.2868 - val_loss: 3.6622 - val_acc: 0.1984 - val_categorical_crossentropy: 3.6622\n",
      "Epoch 262/500\n",
      "8999/8999 [==============================] - 1s 144us/sample - loss: 1.2734 - acc: 0.5438 - categorical_crossentropy: 1.2734 - val_loss: 3.8055 - val_acc: 0.2204 - val_categorical_crossentropy: 3.8055\n",
      "Epoch 263/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2851 - acc: 0.5343 - categorical_crossentropy: 1.2851 - val_loss: 3.7006 - val_acc: 0.2044 - val_categorical_crossentropy: 3.7006\n",
      "Epoch 264/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2836 - acc: 0.5402 - categorical_crossentropy: 1.2836 - val_loss: 3.8044 - val_acc: 0.1964 - val_categorical_crossentropy: 3.8044\n",
      "Epoch 265/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.3078 - acc: 0.5364 - categorical_crossentropy: 1.3078 - val_loss: 3.6399 - val_acc: 0.2084 - val_categorical_crossentropy: 3.6399\n",
      "Epoch 266/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3224 - acc: 0.5358 - categorical_crossentropy: 1.3224 - val_loss: 3.7463 - val_acc: 0.1924 - val_categorical_crossentropy: 3.7463\n",
      "Epoch 267/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2624 - acc: 0.5477 - categorical_crossentropy: 1.2624 - val_loss: 3.7636 - val_acc: 0.2244 - val_categorical_crossentropy: 3.7636\n",
      "Epoch 268/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2820 - acc: 0.5459 - categorical_crossentropy: 1.2820 - val_loss: 3.7480 - val_acc: 0.2024 - val_categorical_crossentropy: 3.7480\n",
      "Epoch 269/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3084 - acc: 0.5354 - categorical_crossentropy: 1.3084 - val_loss: 3.8054 - val_acc: 0.2144 - val_categorical_crossentropy: 3.8054\n",
      "Epoch 270/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2626 - acc: 0.5531 - categorical_crossentropy: 1.2626 - val_loss: 3.8537 - val_acc: 0.1924 - val_categorical_crossentropy: 3.8537\n",
      "Epoch 271/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.2929 - acc: 0.5395 - categorical_crossentropy: 1.2929 - val_loss: 3.8325 - val_acc: 0.2144 - val_categorical_crossentropy: 3.8325\n",
      "Epoch 272/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2558 - acc: 0.5516 - categorical_crossentropy: 1.2558 - val_loss: 3.8247 - val_acc: 0.2064 - val_categorical_crossentropy: 3.8247\n",
      "Epoch 273/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2781 - acc: 0.5425 - categorical_crossentropy: 1.2781 - val_loss: 3.6858 - val_acc: 0.2124 - val_categorical_crossentropy: 3.6858\n",
      "Epoch 274/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2649 - acc: 0.5503 - categorical_crossentropy: 1.2649 - val_loss: 3.9761 - val_acc: 0.2064 - val_categorical_crossentropy: 3.9761\n",
      "Epoch 275/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2496 - acc: 0.5544 - categorical_crossentropy: 1.2496 - val_loss: 3.7863 - val_acc: 0.2024 - val_categorical_crossentropy: 3.7863\n",
      "Epoch 276/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2561 - acc: 0.5524 - categorical_crossentropy: 1.2561 - val_loss: 3.8917 - val_acc: 0.2004 - val_categorical_crossentropy: 3.8917\n",
      "Epoch 277/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.2893 - acc: 0.5428 - categorical_crossentropy: 1.2893 - val_loss: 3.9582 - val_acc: 0.1964 - val_categorical_crossentropy: 3.9582\n",
      "Epoch 278/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2730 - acc: 0.5486 - categorical_crossentropy: 1.2730 - val_loss: 4.0468 - val_acc: 0.1944 - val_categorical_crossentropy: 4.0468\n",
      "Epoch 279/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2726 - acc: 0.5457 - categorical_crossentropy: 1.2726 - val_loss: 3.7795 - val_acc: 0.2024 - val_categorical_crossentropy: 3.7795\n",
      "Epoch 280/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3053 - acc: 0.5413 - categorical_crossentropy: 1.3053 - val_loss: 3.8283 - val_acc: 0.2004 - val_categorical_crossentropy: 3.8283\n",
      "Epoch 281/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.3054 - acc: 0.5344 - categorical_crossentropy: 1.3054 - val_loss: 3.9589 - val_acc: 0.2104 - val_categorical_crossentropy: 3.9589\n",
      "Epoch 282/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2768 - acc: 0.5486 - categorical_crossentropy: 1.2768 - val_loss: 3.8704 - val_acc: 0.2024 - val_categorical_crossentropy: 3.8704\n",
      "Epoch 283/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2759 - acc: 0.5473 - categorical_crossentropy: 1.2759 - val_loss: 3.7746 - val_acc: 0.2004 - val_categorical_crossentropy: 3.7746\n",
      "Epoch 284/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2431 - acc: 0.5568 - categorical_crossentropy: 1.2431 - val_loss: 3.9645 - val_acc: 0.2004 - val_categorical_crossentropy: 3.9645\n",
      "Epoch 285/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2588 - acc: 0.5540 - categorical_crossentropy: 1.2588 - val_loss: 3.9898 - val_acc: 0.2104 - val_categorical_crossentropy: 3.9898\n",
      "Epoch 286/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2495 - acc: 0.5564 - categorical_crossentropy: 1.2495 - val_loss: 3.9508 - val_acc: 0.1924 - val_categorical_crossentropy: 3.9508\n",
      "Epoch 287/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2854 - acc: 0.5402 - categorical_crossentropy: 1.2854 - val_loss: 3.8626 - val_acc: 0.1964 - val_categorical_crossentropy: 3.8626\n",
      "Epoch 288/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2557 - acc: 0.5543 - categorical_crossentropy: 1.2557 - val_loss: 3.7306 - val_acc: 0.2144 - val_categorical_crossentropy: 3.7306\n",
      "Epoch 289/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2474 - acc: 0.5524 - categorical_crossentropy: 1.2474 - val_loss: 3.8049 - val_acc: 0.1904 - val_categorical_crossentropy: 3.8049\n",
      "Epoch 290/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2841 - acc: 0.5432 - categorical_crossentropy: 1.2841 - val_loss: 3.8373 - val_acc: 0.2084 - val_categorical_crossentropy: 3.8373\n",
      "Epoch 291/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2560 - acc: 0.5461 - categorical_crossentropy: 1.2560 - val_loss: 3.9037 - val_acc: 0.2244 - val_categorical_crossentropy: 3.9037\n",
      "Epoch 292/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2493 - acc: 0.5523 - categorical_crossentropy: 1.2493 - val_loss: 3.9695 - val_acc: 0.2184 - val_categorical_crossentropy: 3.9695\n",
      "Epoch 293/500\n",
      "8999/8999 [==============================] - 1s 140us/sample - loss: 1.2782 - acc: 0.5461 - categorical_crossentropy: 1.2782 - val_loss: 3.9099 - val_acc: 0.2305 - val_categorical_crossentropy: 3.9099\n",
      "Epoch 294/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2260 - acc: 0.5613 - categorical_crossentropy: 1.2260 - val_loss: 3.8601 - val_acc: 0.2124 - val_categorical_crossentropy: 3.8601\n",
      "Epoch 295/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2378 - acc: 0.5605 - categorical_crossentropy: 1.2378 - val_loss: 3.8140 - val_acc: 0.1944 - val_categorical_crossentropy: 3.8140\n",
      "Epoch 296/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2471 - acc: 0.5535 - categorical_crossentropy: 1.2471 - val_loss: 3.9501 - val_acc: 0.2084 - val_categorical_crossentropy: 3.9502\n",
      "Epoch 297/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.3352 - acc: 0.5255 - categorical_crossentropy: 1.3352 - val_loss: 3.8584 - val_acc: 0.2024 - val_categorical_crossentropy: 3.8584\n",
      "Epoch 298/500\n",
      "8999/8999 [==============================] - 1s 144us/sample - loss: 1.2749 - acc: 0.5456 - categorical_crossentropy: 1.2749 - val_loss: 3.8868 - val_acc: 0.2064 - val_categorical_crossentropy: 3.8868\n",
      "Epoch 299/500\n",
      "8999/8999 [==============================] - 1s 146us/sample - loss: 1.2451 - acc: 0.5530 - categorical_crossentropy: 1.2451 - val_loss: 3.8643 - val_acc: 0.2184 - val_categorical_crossentropy: 3.8643\n",
      "Epoch 300/500\n",
      "8999/8999 [==============================] - 1s 140us/sample - loss: 1.2506 - acc: 0.5547 - categorical_crossentropy: 1.2506 - val_loss: 3.9559 - val_acc: 0.2204 - val_categorical_crossentropy: 3.9559\n",
      "Epoch 301/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2560 - acc: 0.5444 - categorical_crossentropy: 1.2560 - val_loss: 3.9169 - val_acc: 0.2144 - val_categorical_crossentropy: 3.9169\n",
      "Epoch 302/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2512 - acc: 0.5553 - categorical_crossentropy: 1.2512 - val_loss: 3.8176 - val_acc: 0.2144 - val_categorical_crossentropy: 3.8176\n",
      "Epoch 303/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.2318 - acc: 0.5633 - categorical_crossentropy: 1.2318 - val_loss: 4.0252 - val_acc: 0.2024 - val_categorical_crossentropy: 4.0252\n",
      "Epoch 304/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2572 - acc: 0.5521 - categorical_crossentropy: 1.2572 - val_loss: 3.8247 - val_acc: 0.2124 - val_categorical_crossentropy: 3.8247\n",
      "Epoch 305/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2506 - acc: 0.5547 - categorical_crossentropy: 1.2506 - val_loss: 3.9304 - val_acc: 0.1964 - val_categorical_crossentropy: 3.9304\n",
      "Epoch 306/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2465 - acc: 0.5554 - categorical_crossentropy: 1.2465 - val_loss: 4.0019 - val_acc: 0.1984 - val_categorical_crossentropy: 4.0019\n",
      "Epoch 307/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2697 - acc: 0.5524 - categorical_crossentropy: 1.2697 - val_loss: 3.8036 - val_acc: 0.2184 - val_categorical_crossentropy: 3.8036\n",
      "Epoch 308/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2482 - acc: 0.5580 - categorical_crossentropy: 1.2482 - val_loss: 3.8790 - val_acc: 0.2144 - val_categorical_crossentropy: 3.8790\n",
      "Epoch 309/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2433 - acc: 0.5541 - categorical_crossentropy: 1.2433 - val_loss: 3.8876 - val_acc: 0.2144 - val_categorical_crossentropy: 3.8876\n",
      "Epoch 310/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2926 - acc: 0.5447 - categorical_crossentropy: 1.2926 - val_loss: 3.9245 - val_acc: 0.1984 - val_categorical_crossentropy: 3.9245\n",
      "Epoch 311/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2752 - acc: 0.5483 - categorical_crossentropy: 1.2752 - val_loss: 3.8416 - val_acc: 0.2084 - val_categorical_crossentropy: 3.8416\n",
      "Epoch 312/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2147 - acc: 0.5642 - categorical_crossentropy: 1.2147 - val_loss: 4.0208 - val_acc: 0.2325 - val_categorical_crossentropy: 4.0208\n",
      "Epoch 313/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2460 - acc: 0.5525 - categorical_crossentropy: 1.2460 - val_loss: 3.9359 - val_acc: 0.2064 - val_categorical_crossentropy: 3.9359\n",
      "Epoch 314/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2363 - acc: 0.5541 - categorical_crossentropy: 1.2363 - val_loss: 3.8883 - val_acc: 0.2224 - val_categorical_crossentropy: 3.8883\n",
      "Epoch 315/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2227 - acc: 0.5621 - categorical_crossentropy: 1.2227 - val_loss: 3.9102 - val_acc: 0.1944 - val_categorical_crossentropy: 3.9102\n",
      "Epoch 316/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2661 - acc: 0.5508 - categorical_crossentropy: 1.2661 - val_loss: 3.9276 - val_acc: 0.1864 - val_categorical_crossentropy: 3.9276\n",
      "Epoch 317/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2218 - acc: 0.5598 - categorical_crossentropy: 1.2218 - val_loss: 3.8341 - val_acc: 0.2144 - val_categorical_crossentropy: 3.8341\n",
      "Epoch 318/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2608 - acc: 0.5531 - categorical_crossentropy: 1.2608 - val_loss: 3.8997 - val_acc: 0.2044 - val_categorical_crossentropy: 3.8997\n",
      "Epoch 319/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2417 - acc: 0.5594 - categorical_crossentropy: 1.2417 - val_loss: 3.9577 - val_acc: 0.2184 - val_categorical_crossentropy: 3.9577\n",
      "Epoch 320/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2548 - acc: 0.5567 - categorical_crossentropy: 1.2548 - val_loss: 3.9210 - val_acc: 0.2204 - val_categorical_crossentropy: 3.9210\n",
      "Epoch 321/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2648 - acc: 0.5462 - categorical_crossentropy: 1.2648 - val_loss: 3.9436 - val_acc: 0.1984 - val_categorical_crossentropy: 3.9436\n",
      "Epoch 322/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2130 - acc: 0.5674 - categorical_crossentropy: 1.2130 - val_loss: 3.8652 - val_acc: 0.2204 - val_categorical_crossentropy: 3.8652\n",
      "Epoch 323/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2358 - acc: 0.5607 - categorical_crossentropy: 1.2358 - val_loss: 3.7123 - val_acc: 0.2265 - val_categorical_crossentropy: 3.7123\n",
      "Epoch 324/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2968 - acc: 0.5434 - categorical_crossentropy: 1.2968 - val_loss: 3.8839 - val_acc: 0.2325 - val_categorical_crossentropy: 3.8839\n",
      "Epoch 325/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2323 - acc: 0.5566 - categorical_crossentropy: 1.2323 - val_loss: 3.8185 - val_acc: 0.2124 - val_categorical_crossentropy: 3.8185\n",
      "Epoch 326/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2284 - acc: 0.5597 - categorical_crossentropy: 1.2284 - val_loss: 4.0529 - val_acc: 0.2265 - val_categorical_crossentropy: 4.0529\n",
      "Epoch 327/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2388 - acc: 0.5562 - categorical_crossentropy: 1.2388 - val_loss: 3.8559 - val_acc: 0.2204 - val_categorical_crossentropy: 3.8559\n",
      "Epoch 328/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2303 - acc: 0.5627 - categorical_crossentropy: 1.2303 - val_loss: 3.8727 - val_acc: 0.2265 - val_categorical_crossentropy: 3.8727\n",
      "Epoch 329/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2442 - acc: 0.5586 - categorical_crossentropy: 1.2442 - val_loss: 3.8106 - val_acc: 0.2084 - val_categorical_crossentropy: 3.8106\n",
      "Epoch 330/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2470 - acc: 0.5574 - categorical_crossentropy: 1.2470 - val_loss: 3.8919 - val_acc: 0.2044 - val_categorical_crossentropy: 3.8919\n",
      "Epoch 331/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2419 - acc: 0.5592 - categorical_crossentropy: 1.2419 - val_loss: 3.8676 - val_acc: 0.2124 - val_categorical_crossentropy: 3.8676\n",
      "Epoch 332/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2094 - acc: 0.5687 - categorical_crossentropy: 1.2094 - val_loss: 3.9501 - val_acc: 0.2305 - val_categorical_crossentropy: 3.9501\n",
      "Epoch 333/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2181 - acc: 0.5660 - categorical_crossentropy: 1.2181 - val_loss: 3.9564 - val_acc: 0.2004 - val_categorical_crossentropy: 3.9564\n",
      "Epoch 334/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2279 - acc: 0.5540 - categorical_crossentropy: 1.2279 - val_loss: 3.9290 - val_acc: 0.2124 - val_categorical_crossentropy: 3.9290\n",
      "Epoch 335/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2418 - acc: 0.5552 - categorical_crossentropy: 1.2418 - val_loss: 4.0300 - val_acc: 0.2144 - val_categorical_crossentropy: 4.0300\n",
      "Epoch 336/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2298 - acc: 0.5604 - categorical_crossentropy: 1.2298 - val_loss: 4.1980 - val_acc: 0.1924 - val_categorical_crossentropy: 4.1980\n",
      "Epoch 337/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2501 - acc: 0.5561 - categorical_crossentropy: 1.2501 - val_loss: 3.8761 - val_acc: 0.2164 - val_categorical_crossentropy: 3.8761\n",
      "Epoch 338/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2179 - acc: 0.5646 - categorical_crossentropy: 1.2179 - val_loss: 3.9240 - val_acc: 0.1984 - val_categorical_crossentropy: 3.9240\n",
      "Epoch 339/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2161 - acc: 0.5728 - categorical_crossentropy: 1.2161 - val_loss: 4.0161 - val_acc: 0.2004 - val_categorical_crossentropy: 4.0161\n",
      "Epoch 340/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2395 - acc: 0.5618 - categorical_crossentropy: 1.2395 - val_loss: 3.9735 - val_acc: 0.2224 - val_categorical_crossentropy: 3.9735\n",
      "Epoch 341/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1905 - acc: 0.5786 - categorical_crossentropy: 1.1905 - val_loss: 3.9933 - val_acc: 0.2044 - val_categorical_crossentropy: 3.9933\n",
      "Epoch 342/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1873 - acc: 0.5767 - categorical_crossentropy: 1.1873 - val_loss: 3.9775 - val_acc: 0.2124 - val_categorical_crossentropy: 3.9775\n",
      "Epoch 343/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2245 - acc: 0.5627 - categorical_crossentropy: 1.2245 - val_loss: 3.9668 - val_acc: 0.2004 - val_categorical_crossentropy: 3.9668\n",
      "Epoch 344/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2392 - acc: 0.5554 - categorical_crossentropy: 1.2392 - val_loss: 3.9423 - val_acc: 0.2144 - val_categorical_crossentropy: 3.9423\n",
      "Epoch 345/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2457 - acc: 0.5545 - categorical_crossentropy: 1.2457 - val_loss: 4.0017 - val_acc: 0.2204 - val_categorical_crossentropy: 4.0017\n",
      "Epoch 346/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2070 - acc: 0.5680 - categorical_crossentropy: 1.2070 - val_loss: 3.9079 - val_acc: 0.2024 - val_categorical_crossentropy: 3.9079\n",
      "Epoch 347/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2207 - acc: 0.5607 - categorical_crossentropy: 1.2207 - val_loss: 3.8862 - val_acc: 0.2144 - val_categorical_crossentropy: 3.8862\n",
      "Epoch 348/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.2204 - acc: 0.5625 - categorical_crossentropy: 1.2204 - val_loss: 3.9145 - val_acc: 0.2285 - val_categorical_crossentropy: 3.9145\n",
      "Epoch 349/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.2243 - acc: 0.5676 - categorical_crossentropy: 1.2243 - val_loss: 3.9115 - val_acc: 0.1804 - val_categorical_crossentropy: 3.9115\n",
      "Epoch 350/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.3336 - acc: 0.5311 - categorical_crossentropy: 1.3336 - val_loss: 3.8467 - val_acc: 0.2144 - val_categorical_crossentropy: 3.8467\n",
      "Epoch 351/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2203 - acc: 0.5637 - categorical_crossentropy: 1.2203 - val_loss: 3.9964 - val_acc: 0.2064 - val_categorical_crossentropy: 3.9964\n",
      "Epoch 352/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2001 - acc: 0.5745 - categorical_crossentropy: 1.2001 - val_loss: 4.1401 - val_acc: 0.2144 - val_categorical_crossentropy: 4.1401\n",
      "Epoch 353/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2227 - acc: 0.5610 - categorical_crossentropy: 1.2227 - val_loss: 3.9411 - val_acc: 0.2104 - val_categorical_crossentropy: 3.9411\n",
      "Epoch 354/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2292 - acc: 0.5607 - categorical_crossentropy: 1.2292 - val_loss: 4.0380 - val_acc: 0.2104 - val_categorical_crossentropy: 4.0380\n",
      "Epoch 355/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1963 - acc: 0.5711 - categorical_crossentropy: 1.1963 - val_loss: 3.9420 - val_acc: 0.2084 - val_categorical_crossentropy: 3.9420\n",
      "Epoch 356/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2505 - acc: 0.5604 - categorical_crossentropy: 1.2505 - val_loss: 3.9210 - val_acc: 0.2004 - val_categorical_crossentropy: 3.9210\n",
      "Epoch 357/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2001 - acc: 0.5710 - categorical_crossentropy: 1.2001 - val_loss: 3.9529 - val_acc: 0.2104 - val_categorical_crossentropy: 3.9529\n",
      "Epoch 358/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.2304 - acc: 0.5613 - categorical_crossentropy: 1.2304 - val_loss: 4.0864 - val_acc: 0.1924 - val_categorical_crossentropy: 4.0864\n",
      "Epoch 359/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1958 - acc: 0.5720 - categorical_crossentropy: 1.1958 - val_loss: 3.9589 - val_acc: 0.2084 - val_categorical_crossentropy: 3.9589\n",
      "Epoch 360/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1942 - acc: 0.5686 - categorical_crossentropy: 1.1942 - val_loss: 3.9970 - val_acc: 0.2044 - val_categorical_crossentropy: 3.9970\n",
      "Epoch 361/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1888 - acc: 0.5767 - categorical_crossentropy: 1.1888 - val_loss: 4.1609 - val_acc: 0.2144 - val_categorical_crossentropy: 4.1609\n",
      "Epoch 362/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2210 - acc: 0.5622 - categorical_crossentropy: 1.2210 - val_loss: 4.1154 - val_acc: 0.2024 - val_categorical_crossentropy: 4.1154\n",
      "Epoch 363/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2157 - acc: 0.5647 - categorical_crossentropy: 1.2157 - val_loss: 4.0457 - val_acc: 0.2305 - val_categorical_crossentropy: 4.0457\n",
      "Epoch 364/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.1964 - acc: 0.5687 - categorical_crossentropy: 1.1964 - val_loss: 4.1104 - val_acc: 0.2164 - val_categorical_crossentropy: 4.1104\n",
      "Epoch 365/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1833 - acc: 0.5753 - categorical_crossentropy: 1.1833 - val_loss: 4.0060 - val_acc: 0.2044 - val_categorical_crossentropy: 4.0060\n",
      "Epoch 366/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2145 - acc: 0.5640 - categorical_crossentropy: 1.2145 - val_loss: 3.8681 - val_acc: 0.1964 - val_categorical_crossentropy: 3.8681\n",
      "Epoch 367/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2493 - acc: 0.5564 - categorical_crossentropy: 1.2493 - val_loss: 3.9222 - val_acc: 0.2144 - val_categorical_crossentropy: 3.9222\n",
      "Epoch 368/500\n",
      "8999/8999 [==============================] - 1s 132us/sample - loss: 1.2077 - acc: 0.5667 - categorical_crossentropy: 1.2077 - val_loss: 3.9111 - val_acc: 0.2064 - val_categorical_crossentropy: 3.9111\n",
      "Epoch 369/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.2121 - acc: 0.5565 - categorical_crossentropy: 1.2121 - val_loss: 4.0459 - val_acc: 0.2024 - val_categorical_crossentropy: 4.0459\n",
      "Epoch 370/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2118 - acc: 0.5691 - categorical_crossentropy: 1.2118 - val_loss: 3.9941 - val_acc: 0.2064 - val_categorical_crossentropy: 3.9941\n",
      "Epoch 371/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2163 - acc: 0.5635 - categorical_crossentropy: 1.2163 - val_loss: 3.9350 - val_acc: 0.2104 - val_categorical_crossentropy: 3.9350\n",
      "Epoch 372/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1898 - acc: 0.5721 - categorical_crossentropy: 1.1898 - val_loss: 4.0228 - val_acc: 0.1964 - val_categorical_crossentropy: 4.0228\n",
      "Epoch 373/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1954 - acc: 0.5733 - categorical_crossentropy: 1.1954 - val_loss: 3.9617 - val_acc: 0.2224 - val_categorical_crossentropy: 3.9617\n",
      "Epoch 374/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1716 - acc: 0.5780 - categorical_crossentropy: 1.1716 - val_loss: 4.1528 - val_acc: 0.2104 - val_categorical_crossentropy: 4.1528\n",
      "Epoch 375/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2360 - acc: 0.5602 - categorical_crossentropy: 1.2360 - val_loss: 3.8575 - val_acc: 0.1944 - val_categorical_crossentropy: 3.8575\n",
      "Epoch 376/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1790 - acc: 0.5785 - categorical_crossentropy: 1.1790 - val_loss: 4.1448 - val_acc: 0.1984 - val_categorical_crossentropy: 4.1448\n",
      "Epoch 377/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2225 - acc: 0.5624 - categorical_crossentropy: 1.2225 - val_loss: 4.0035 - val_acc: 0.2204 - val_categorical_crossentropy: 4.0035\n",
      "Epoch 378/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.2067 - acc: 0.5730 - categorical_crossentropy: 1.2067 - val_loss: 3.9018 - val_acc: 0.2044 - val_categorical_crossentropy: 3.9018\n",
      "Epoch 379/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2183 - acc: 0.5646 - categorical_crossentropy: 1.2183 - val_loss: 4.0919 - val_acc: 0.2084 - val_categorical_crossentropy: 4.0919\n",
      "Epoch 380/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1850 - acc: 0.5731 - categorical_crossentropy: 1.1850 - val_loss: 4.0196 - val_acc: 0.2084 - val_categorical_crossentropy: 4.0196\n",
      "Epoch 381/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2167 - acc: 0.5688 - categorical_crossentropy: 1.2167 - val_loss: 3.8856 - val_acc: 0.2104 - val_categorical_crossentropy: 3.8856\n",
      "Epoch 382/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2018 - acc: 0.5681 - categorical_crossentropy: 1.2018 - val_loss: 4.0159 - val_acc: 0.2104 - val_categorical_crossentropy: 4.0159\n",
      "Epoch 383/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2200 - acc: 0.5602 - categorical_crossentropy: 1.2200 - val_loss: 4.1515 - val_acc: 0.2044 - val_categorical_crossentropy: 4.1515\n",
      "Epoch 384/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1971 - acc: 0.5682 - categorical_crossentropy: 1.1971 - val_loss: 4.1476 - val_acc: 0.2244 - val_categorical_crossentropy: 4.1476\n",
      "Epoch 385/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2163 - acc: 0.5654 - categorical_crossentropy: 1.2163 - val_loss: 3.9052 - val_acc: 0.2044 - val_categorical_crossentropy: 3.9052\n",
      "Epoch 386/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2482 - acc: 0.5527 - categorical_crossentropy: 1.2482 - val_loss: 4.0500 - val_acc: 0.2144 - val_categorical_crossentropy: 4.0500\n",
      "Epoch 387/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1929 - acc: 0.5731 - categorical_crossentropy: 1.1929 - val_loss: 4.0527 - val_acc: 0.1944 - val_categorical_crossentropy: 4.0527\n",
      "Epoch 388/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.1896 - acc: 0.5732 - categorical_crossentropy: 1.1896 - val_loss: 4.0657 - val_acc: 0.1964 - val_categorical_crossentropy: 4.0657\n",
      "Epoch 389/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.1727 - acc: 0.5763 - categorical_crossentropy: 1.1727 - val_loss: 4.1131 - val_acc: 0.2064 - val_categorical_crossentropy: 4.1131\n",
      "Epoch 390/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1871 - acc: 0.5772 - categorical_crossentropy: 1.1871 - val_loss: 3.9453 - val_acc: 0.2024 - val_categorical_crossentropy: 3.9453\n",
      "Epoch 391/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2112 - acc: 0.5700 - categorical_crossentropy: 1.2112 - val_loss: 4.1073 - val_acc: 0.2044 - val_categorical_crossentropy: 4.1073\n",
      "Epoch 392/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2046 - acc: 0.5754 - categorical_crossentropy: 1.2046 - val_loss: 4.0423 - val_acc: 0.2204 - val_categorical_crossentropy: 4.0423\n",
      "Epoch 393/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1944 - acc: 0.5763 - categorical_crossentropy: 1.1944 - val_loss: 4.2835 - val_acc: 0.2004 - val_categorical_crossentropy: 4.2835\n",
      "Epoch 394/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.1901 - acc: 0.5766 - categorical_crossentropy: 1.1901 - val_loss: 4.0183 - val_acc: 0.2104 - val_categorical_crossentropy: 4.0183\n",
      "Epoch 395/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1962 - acc: 0.5731 - categorical_crossentropy: 1.1962 - val_loss: 4.1492 - val_acc: 0.2044 - val_categorical_crossentropy: 4.1492\n",
      "Epoch 396/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1885 - acc: 0.5777 - categorical_crossentropy: 1.1885 - val_loss: 3.9514 - val_acc: 0.2104 - val_categorical_crossentropy: 3.9514\n",
      "Epoch 397/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1821 - acc: 0.5797 - categorical_crossentropy: 1.1821 - val_loss: 4.0736 - val_acc: 0.2204 - val_categorical_crossentropy: 4.0736\n",
      "Epoch 398/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1953 - acc: 0.5702 - categorical_crossentropy: 1.1953 - val_loss: 4.0458 - val_acc: 0.2104 - val_categorical_crossentropy: 4.0458\n",
      "Epoch 399/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.1725 - acc: 0.5786 - categorical_crossentropy: 1.1725 - val_loss: 4.0928 - val_acc: 0.2144 - val_categorical_crossentropy: 4.0928\n",
      "Epoch 400/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1771 - acc: 0.5786 - categorical_crossentropy: 1.1771 - val_loss: 4.1779 - val_acc: 0.2064 - val_categorical_crossentropy: 4.1779\n",
      "Epoch 401/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1571 - acc: 0.5844 - categorical_crossentropy: 1.1571 - val_loss: 4.2015 - val_acc: 0.2104 - val_categorical_crossentropy: 4.2015\n",
      "Epoch 402/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.1973 - acc: 0.5765 - categorical_crossentropy: 1.1973 - val_loss: 4.0930 - val_acc: 0.2084 - val_categorical_crossentropy: 4.0930\n",
      "Epoch 403/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2146 - acc: 0.5651 - categorical_crossentropy: 1.2146 - val_loss: 3.9731 - val_acc: 0.2164 - val_categorical_crossentropy: 3.9731\n",
      "Epoch 404/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1672 - acc: 0.5808 - categorical_crossentropy: 1.1672 - val_loss: 4.0658 - val_acc: 0.1964 - val_categorical_crossentropy: 4.0658\n",
      "Epoch 405/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2011 - acc: 0.5695 - categorical_crossentropy: 1.2011 - val_loss: 4.0261 - val_acc: 0.2104 - val_categorical_crossentropy: 4.0261\n",
      "Epoch 406/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1364 - acc: 0.5956 - categorical_crossentropy: 1.1364 - val_loss: 4.1309 - val_acc: 0.2104 - val_categorical_crossentropy: 4.1309\n",
      "Epoch 407/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1664 - acc: 0.5843 - categorical_crossentropy: 1.1664 - val_loss: 4.2561 - val_acc: 0.2024 - val_categorical_crossentropy: 4.2561\n",
      "Epoch 408/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1778 - acc: 0.5748 - categorical_crossentropy: 1.1778 - val_loss: 4.0363 - val_acc: 0.2365 - val_categorical_crossentropy: 4.0363\n",
      "Epoch 409/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2031 - acc: 0.5670 - categorical_crossentropy: 1.2031 - val_loss: 4.1707 - val_acc: 0.2064 - val_categorical_crossentropy: 4.1707\n",
      "Epoch 410/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1611 - acc: 0.5854 - categorical_crossentropy: 1.1611 - val_loss: 4.1865 - val_acc: 0.2084 - val_categorical_crossentropy: 4.1865\n",
      "Epoch 411/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2155 - acc: 0.5668 - categorical_crossentropy: 1.2155 - val_loss: 4.0791 - val_acc: 0.2204 - val_categorical_crossentropy: 4.0791\n",
      "Epoch 412/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2484 - acc: 0.5593 - categorical_crossentropy: 1.2484 - val_loss: 4.0030 - val_acc: 0.2104 - val_categorical_crossentropy: 4.0030\n",
      "Epoch 413/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1736 - acc: 0.5830 - categorical_crossentropy: 1.1736 - val_loss: 4.0185 - val_acc: 0.2104 - val_categorical_crossentropy: 4.0185\n",
      "Epoch 414/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1433 - acc: 0.5870 - categorical_crossentropy: 1.1433 - val_loss: 4.3238 - val_acc: 0.1984 - val_categorical_crossentropy: 4.3238\n",
      "Epoch 415/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1802 - acc: 0.5750 - categorical_crossentropy: 1.1802 - val_loss: 4.0745 - val_acc: 0.1984 - val_categorical_crossentropy: 4.0745\n",
      "Epoch 416/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.1989 - acc: 0.5720 - categorical_crossentropy: 1.1989 - val_loss: 3.9527 - val_acc: 0.2064 - val_categorical_crossentropy: 3.9527\n",
      "Epoch 417/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.2351 - acc: 0.5685 - categorical_crossentropy: 1.2351 - val_loss: 4.0058 - val_acc: 0.1924 - val_categorical_crossentropy: 4.0058\n",
      "Epoch 418/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.2088 - acc: 0.5724 - categorical_crossentropy: 1.2088 - val_loss: 3.9727 - val_acc: 0.2244 - val_categorical_crossentropy: 3.9727\n",
      "Epoch 419/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1553 - acc: 0.5911 - categorical_crossentropy: 1.1553 - val_loss: 4.0577 - val_acc: 0.2084 - val_categorical_crossentropy: 4.0577\n",
      "Epoch 420/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1913 - acc: 0.5777 - categorical_crossentropy: 1.1913 - val_loss: 4.0639 - val_acc: 0.2124 - val_categorical_crossentropy: 4.0639\n",
      "Epoch 421/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1568 - acc: 0.5855 - categorical_crossentropy: 1.1568 - val_loss: 4.0644 - val_acc: 0.2124 - val_categorical_crossentropy: 4.0644\n",
      "Epoch 422/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1587 - acc: 0.5906 - categorical_crossentropy: 1.1587 - val_loss: 4.1006 - val_acc: 0.2285 - val_categorical_crossentropy: 4.1006\n",
      "Epoch 423/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1422 - acc: 0.5890 - categorical_crossentropy: 1.1422 - val_loss: 4.1769 - val_acc: 0.2204 - val_categorical_crossentropy: 4.1769\n",
      "Epoch 424/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.2508 - acc: 0.5566 - categorical_crossentropy: 1.2508 - val_loss: 4.0096 - val_acc: 0.2044 - val_categorical_crossentropy: 4.0096\n",
      "Epoch 425/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.1684 - acc: 0.5826 - categorical_crossentropy: 1.1684 - val_loss: 4.1565 - val_acc: 0.2004 - val_categorical_crossentropy: 4.1565\n",
      "Epoch 426/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1580 - acc: 0.5847 - categorical_crossentropy: 1.1580 - val_loss: 4.0749 - val_acc: 0.2104 - val_categorical_crossentropy: 4.0749\n",
      "Epoch 427/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.1846 - acc: 0.5771 - categorical_crossentropy: 1.1846 - val_loss: 4.1618 - val_acc: 0.2044 - val_categorical_crossentropy: 4.1618\n",
      "Epoch 428/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1393 - acc: 0.5912 - categorical_crossentropy: 1.1393 - val_loss: 4.0599 - val_acc: 0.2244 - val_categorical_crossentropy: 4.0599\n",
      "Epoch 429/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1426 - acc: 0.5837 - categorical_crossentropy: 1.1426 - val_loss: 4.0346 - val_acc: 0.2064 - val_categorical_crossentropy: 4.0346\n",
      "Epoch 430/500\n",
      "8999/8999 [==============================] - 1s 141us/sample - loss: 1.1906 - acc: 0.5721 - categorical_crossentropy: 1.1906 - val_loss: 4.0499 - val_acc: 0.1944 - val_categorical_crossentropy: 4.0499\n",
      "Epoch 431/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1828 - acc: 0.5764 - categorical_crossentropy: 1.1828 - val_loss: 4.1883 - val_acc: 0.2044 - val_categorical_crossentropy: 4.1883\n",
      "Epoch 432/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1721 - acc: 0.5783 - categorical_crossentropy: 1.1721 - val_loss: 3.9795 - val_acc: 0.2084 - val_categorical_crossentropy: 3.9795\n",
      "Epoch 433/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1589 - acc: 0.5834 - categorical_crossentropy: 1.1589 - val_loss: 4.0953 - val_acc: 0.2104 - val_categorical_crossentropy: 4.0953\n",
      "Epoch 434/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2122 - acc: 0.5684 - categorical_crossentropy: 1.2122 - val_loss: 4.0005 - val_acc: 0.2064 - val_categorical_crossentropy: 4.0005\n",
      "Epoch 435/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2102 - acc: 0.5695 - categorical_crossentropy: 1.2102 - val_loss: 4.0368 - val_acc: 0.2064 - val_categorical_crossentropy: 4.0368\n",
      "Epoch 436/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.1676 - acc: 0.5777 - categorical_crossentropy: 1.1676 - val_loss: 4.0374 - val_acc: 0.2204 - val_categorical_crossentropy: 4.0374\n",
      "Epoch 437/500\n",
      "8999/8999 [==============================] - 1s 139us/sample - loss: 1.1209 - acc: 0.5953 - categorical_crossentropy: 1.1209 - val_loss: 4.2072 - val_acc: 0.2124 - val_categorical_crossentropy: 4.2072\n",
      "Epoch 438/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.1235 - acc: 0.6007 - categorical_crossentropy: 1.1235 - val_loss: 4.2434 - val_acc: 0.1904 - val_categorical_crossentropy: 4.2434\n",
      "Epoch 439/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.1327 - acc: 0.5886 - categorical_crossentropy: 1.1327 - val_loss: 4.1115 - val_acc: 0.2044 - val_categorical_crossentropy: 4.1115\n",
      "Epoch 440/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.1795 - acc: 0.5747 - categorical_crossentropy: 1.1795 - val_loss: 4.1994 - val_acc: 0.1904 - val_categorical_crossentropy: 4.1994\n",
      "Epoch 441/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1353 - acc: 0.5896 - categorical_crossentropy: 1.1353 - val_loss: 4.1259 - val_acc: 0.2044 - val_categorical_crossentropy: 4.1259\n",
      "Epoch 442/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2015 - acc: 0.5754 - categorical_crossentropy: 1.2015 - val_loss: 4.1326 - val_acc: 0.2044 - val_categorical_crossentropy: 4.1326\n",
      "Epoch 443/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1519 - acc: 0.5894 - categorical_crossentropy: 1.1519 - val_loss: 4.1341 - val_acc: 0.2265 - val_categorical_crossentropy: 4.1341\n",
      "Epoch 444/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1118 - acc: 0.5977 - categorical_crossentropy: 1.1118 - val_loss: 4.2209 - val_acc: 0.1924 - val_categorical_crossentropy: 4.2209\n",
      "Epoch 445/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1517 - acc: 0.5901 - categorical_crossentropy: 1.1517 - val_loss: 4.1919 - val_acc: 0.2265 - val_categorical_crossentropy: 4.1919\n",
      "Epoch 446/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1367 - acc: 0.5914 - categorical_crossentropy: 1.1367 - val_loss: 4.1962 - val_acc: 0.2184 - val_categorical_crossentropy: 4.1962\n",
      "Epoch 447/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2139 - acc: 0.5700 - categorical_crossentropy: 1.2139 - val_loss: 4.1345 - val_acc: 0.1984 - val_categorical_crossentropy: 4.1345\n",
      "Epoch 448/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1498 - acc: 0.5935 - categorical_crossentropy: 1.1498 - val_loss: 4.1059 - val_acc: 0.2224 - val_categorical_crossentropy: 4.1059\n",
      "Epoch 449/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1383 - acc: 0.5944 - categorical_crossentropy: 1.1383 - val_loss: 4.3397 - val_acc: 0.2044 - val_categorical_crossentropy: 4.3397\n",
      "Epoch 450/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1072 - acc: 0.6001 - categorical_crossentropy: 1.1072 - val_loss: 4.2241 - val_acc: 0.1944 - val_categorical_crossentropy: 4.2241\n",
      "Epoch 451/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1780 - acc: 0.5762 - categorical_crossentropy: 1.1780 - val_loss: 4.0007 - val_acc: 0.2084 - val_categorical_crossentropy: 4.0007\n",
      "Epoch 452/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1231 - acc: 0.6010 - categorical_crossentropy: 1.1231 - val_loss: 4.1289 - val_acc: 0.2325 - val_categorical_crossentropy: 4.1289\n",
      "Epoch 453/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1376 - acc: 0.5905 - categorical_crossentropy: 1.1376 - val_loss: 4.2604 - val_acc: 0.2104 - val_categorical_crossentropy: 4.2604\n",
      "Epoch 454/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1348 - acc: 0.5953 - categorical_crossentropy: 1.1348 - val_loss: 4.2531 - val_acc: 0.2244 - val_categorical_crossentropy: 4.2531\n",
      "Epoch 455/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1621 - acc: 0.5852 - categorical_crossentropy: 1.1621 - val_loss: 4.1986 - val_acc: 0.2004 - val_categorical_crossentropy: 4.1986\n",
      "Epoch 456/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1103 - acc: 0.5982 - categorical_crossentropy: 1.1103 - val_loss: 4.3678 - val_acc: 0.2124 - val_categorical_crossentropy: 4.3678\n",
      "Epoch 457/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.1834 - acc: 0.5722 - categorical_crossentropy: 1.1834 - val_loss: 4.1677 - val_acc: 0.2024 - val_categorical_crossentropy: 4.1677\n",
      "Epoch 458/500\n",
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.1284 - acc: 0.5932 - categorical_crossentropy: 1.1284 - val_loss: 4.4886 - val_acc: 0.2064 - val_categorical_crossentropy: 4.4886\n",
      "Epoch 459/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1092 - acc: 0.6010 - categorical_crossentropy: 1.1092 - val_loss: 4.2062 - val_acc: 0.2184 - val_categorical_crossentropy: 4.2062\n",
      "Epoch 460/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1325 - acc: 0.5950 - categorical_crossentropy: 1.1325 - val_loss: 4.3443 - val_acc: 0.2184 - val_categorical_crossentropy: 4.3443\n",
      "Epoch 461/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.2042 - acc: 0.5791 - categorical_crossentropy: 1.2042 - val_loss: 4.1718 - val_acc: 0.2024 - val_categorical_crossentropy: 4.1718\n",
      "Epoch 462/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1496 - acc: 0.5950 - categorical_crossentropy: 1.1496 - val_loss: 4.2552 - val_acc: 0.2164 - val_categorical_crossentropy: 4.2552\n",
      "Epoch 463/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1359 - acc: 0.5924 - categorical_crossentropy: 1.1359 - val_loss: 4.2437 - val_acc: 0.2044 - val_categorical_crossentropy: 4.2437\n",
      "Epoch 464/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.0969 - acc: 0.6022 - categorical_crossentropy: 1.0969 - val_loss: 4.3480 - val_acc: 0.2064 - val_categorical_crossentropy: 4.3480\n",
      "Epoch 465/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1350 - acc: 0.5880 - categorical_crossentropy: 1.1350 - val_loss: 4.0465 - val_acc: 0.2004 - val_categorical_crossentropy: 4.0465\n",
      "Epoch 466/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1705 - acc: 0.5794 - categorical_crossentropy: 1.1705 - val_loss: 4.0803 - val_acc: 0.2044 - val_categorical_crossentropy: 4.0803\n",
      "Epoch 467/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1525 - acc: 0.5900 - categorical_crossentropy: 1.1525 - val_loss: 4.1244 - val_acc: 0.2044 - val_categorical_crossentropy: 4.1244\n",
      "Epoch 468/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.1289 - acc: 0.5985 - categorical_crossentropy: 1.1289 - val_loss: 4.1933 - val_acc: 0.2024 - val_categorical_crossentropy: 4.1933\n",
      "Epoch 469/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1101 - acc: 0.6026 - categorical_crossentropy: 1.1101 - val_loss: 4.2843 - val_acc: 0.2024 - val_categorical_crossentropy: 4.2843\n",
      "Epoch 470/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1212 - acc: 0.5986 - categorical_crossentropy: 1.1212 - val_loss: 4.2041 - val_acc: 0.2244 - val_categorical_crossentropy: 4.2041\n",
      "Epoch 471/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1511 - acc: 0.5868 - categorical_crossentropy: 1.1511 - val_loss: 4.1556 - val_acc: 0.2164 - val_categorical_crossentropy: 4.1556\n",
      "Epoch 472/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1529 - acc: 0.5890 - categorical_crossentropy: 1.1529 - val_loss: 4.1514 - val_acc: 0.2204 - val_categorical_crossentropy: 4.1514\n",
      "Epoch 473/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1208 - acc: 0.5974 - categorical_crossentropy: 1.1208 - val_loss: 4.4654 - val_acc: 0.1904 - val_categorical_crossentropy: 4.4654\n",
      "Epoch 474/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1193 - acc: 0.5977 - categorical_crossentropy: 1.1193 - val_loss: 4.3176 - val_acc: 0.1964 - val_categorical_crossentropy: 4.3176\n",
      "Epoch 475/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1383 - acc: 0.5860 - categorical_crossentropy: 1.1383 - val_loss: 4.1928 - val_acc: 0.2084 - val_categorical_crossentropy: 4.1928\n",
      "Epoch 476/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1279 - acc: 0.5947 - categorical_crossentropy: 1.1279 - val_loss: 4.2698 - val_acc: 0.2084 - val_categorical_crossentropy: 4.2698\n",
      "Epoch 477/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1215 - acc: 0.5973 - categorical_crossentropy: 1.1215 - val_loss: 4.2731 - val_acc: 0.2064 - val_categorical_crossentropy: 4.2731\n",
      "Epoch 478/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1266 - acc: 0.5945 - categorical_crossentropy: 1.1266 - val_loss: 4.0487 - val_acc: 0.2164 - val_categorical_crossentropy: 4.0487\n",
      "Epoch 479/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1786 - acc: 0.5740 - categorical_crossentropy: 1.1786 - val_loss: 4.2103 - val_acc: 0.2064 - val_categorical_crossentropy: 4.2103\n",
      "Epoch 480/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1496 - acc: 0.5864 - categorical_crossentropy: 1.1496 - val_loss: 4.3470 - val_acc: 0.1884 - val_categorical_crossentropy: 4.3470\n",
      "Epoch 481/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1522 - acc: 0.5907 - categorical_crossentropy: 1.1522 - val_loss: 4.2753 - val_acc: 0.1864 - val_categorical_crossentropy: 4.2753\n",
      "Epoch 482/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1284 - acc: 0.5925 - categorical_crossentropy: 1.1284 - val_loss: 4.2574 - val_acc: 0.1964 - val_categorical_crossentropy: 4.2574\n",
      "Epoch 483/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1292 - acc: 0.5971 - categorical_crossentropy: 1.1292 - val_loss: 4.1817 - val_acc: 0.2064 - val_categorical_crossentropy: 4.1817\n",
      "Epoch 484/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1161 - acc: 0.6010 - categorical_crossentropy: 1.1161 - val_loss: 4.3418 - val_acc: 0.2004 - val_categorical_crossentropy: 4.3418\n",
      "Epoch 485/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1393 - acc: 0.5947 - categorical_crossentropy: 1.1393 - val_loss: 4.2864 - val_acc: 0.2124 - val_categorical_crossentropy: 4.2864\n",
      "Epoch 486/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1347 - acc: 0.5905 - categorical_crossentropy: 1.1347 - val_loss: 4.2350 - val_acc: 0.1964 - val_categorical_crossentropy: 4.2350\n",
      "Epoch 487/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1407 - acc: 0.5828 - categorical_crossentropy: 1.1407 - val_loss: 4.2230 - val_acc: 0.2004 - val_categorical_crossentropy: 4.2230\n",
      "Epoch 488/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1196 - acc: 0.5995 - categorical_crossentropy: 1.1196 - val_loss: 4.2793 - val_acc: 0.2164 - val_categorical_crossentropy: 4.2793\n",
      "Epoch 489/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1502 - acc: 0.5891 - categorical_crossentropy: 1.1502 - val_loss: 4.1324 - val_acc: 0.2164 - val_categorical_crossentropy: 4.1324\n",
      "Epoch 490/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1138 - acc: 0.5991 - categorical_crossentropy: 1.1138 - val_loss: 4.2234 - val_acc: 0.2164 - val_categorical_crossentropy: 4.2234\n",
      "Epoch 491/500\n",
      "8999/8999 [==============================] - 1s 137us/sample - loss: 1.1256 - acc: 0.5960 - categorical_crossentropy: 1.1256 - val_loss: 4.2212 - val_acc: 0.2004 - val_categorical_crossentropy: 4.2212\n",
      "Epoch 492/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1505 - acc: 0.5864 - categorical_crossentropy: 1.1505 - val_loss: 4.1081 - val_acc: 0.2144 - val_categorical_crossentropy: 4.1081\n",
      "Epoch 493/500\n",
      "8999/8999 [==============================] - 1s 138us/sample - loss: 1.1489 - acc: 0.5878 - categorical_crossentropy: 1.1489 - val_loss: 4.0296 - val_acc: 0.2244 - val_categorical_crossentropy: 4.0296\n",
      "Epoch 494/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1347 - acc: 0.5980 - categorical_crossentropy: 1.1347 - val_loss: 4.3178 - val_acc: 0.2124 - val_categorical_crossentropy: 4.3178\n",
      "Epoch 495/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8999/8999 [==============================] - 1s 134us/sample - loss: 1.1559 - acc: 0.5833 - categorical_crossentropy: 1.1559 - val_loss: 4.1591 - val_acc: 0.2024 - val_categorical_crossentropy: 4.1591\n",
      "Epoch 496/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1290 - acc: 0.6016 - categorical_crossentropy: 1.1290 - val_loss: 4.1013 - val_acc: 0.2104 - val_categorical_crossentropy: 4.1013\n",
      "Epoch 497/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.0874 - acc: 0.6117 - categorical_crossentropy: 1.0874 - val_loss: 4.5116 - val_acc: 0.1924 - val_categorical_crossentropy: 4.5116\n",
      "Epoch 498/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1044 - acc: 0.6030 - categorical_crossentropy: 1.1044 - val_loss: 4.2940 - val_acc: 0.2064 - val_categorical_crossentropy: 4.2940\n",
      "Epoch 499/500\n",
      "8999/8999 [==============================] - 1s 135us/sample - loss: 1.1219 - acc: 0.5994 - categorical_crossentropy: 1.1219 - val_loss: 4.2943 - val_acc: 0.1844 - val_categorical_crossentropy: 4.2943\n",
      "Epoch 500/500\n",
      "8999/8999 [==============================] - 1s 136us/sample - loss: 1.1350 - acc: 0.5867 - categorical_crossentropy: 1.1350 - val_loss: 4.3333 - val_acc: 0.1904 - val_categorical_crossentropy: 4.3333\n",
      "CPU times: user 20min 5s, sys: 8min 17s, total: 28min 22s\n",
      "Wall time: 10min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get neural network history\n",
    "# Change batch size (inspect what happens with each ITERATION, not EPOCH)\n",
    "# History is the progress of our neural network, will be used to plot cost functions\n",
    "nn_history = nn_model.fit(train, train_labels, epochs=NUM_EPOCHS, verbose=1,\n",
    "         validation_data=(validate, validate_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f20d4da61d0>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot metrics\n",
    "def plot_history(history):\n",
    "    hist = pd.DataFrame(history.history)\n",
    "    hist['epoch'] = history.epoch\n",
    "\n",
    "    plt.figure()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Cross Entropy Error')\n",
    "    plt.plot(hist['epoch'], hist['categorical_crossentropy'],\n",
    "           label='Train Error')\n",
    "    plt.plot(hist['epoch'], hist['val_categorical_crossentropy'],\n",
    "           label = 'Val Error')\n",
    "    plt.ylim([1,8])\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "plot_history(nn_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy: 58.67318511009216%\n"
     ]
    }
   ],
   "source": [
    "# See Training Accuracy\n",
    "hist = pd.DataFrame(nn_history.history)\n",
    "accuracy_vec = hist.pop(\"acc\")\n",
    "finalAcc = accuracy_vec[len(accuracy_vec) - 1]\n",
    "print(\"Final accuracy: {}%\".format(finalAcc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expects list\n",
    "def accuracy(predictions, true_label):\n",
    "    count = 0\n",
    "    total = len(predictions)\n",
    "    for i in range(total):\n",
    "        if predictions[i] == true_label[i]:\n",
    "            count += 1\n",
    "    return float(count) / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0499001996007984"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test accuracy:\n",
    "y_prob = nn_model.predict(test)\n",
    "y_classes = y_prob.argmax(axis=-1)\n",
    "accuracy(y_classes, testy_integer_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Logistic Regression Model\n",
    "df2 = pd.read_pickle(\"./data/pandas-pickle-small.pkl\")\n",
    "df2 = df2.sample(frac=1, random_state=2).reset_index(drop=True) # Shuffles data\n",
    "# # print(\"This is our X: \", df2.iloc[:, ]\n",
    "numTrain = 9000\n",
    "numTest = 1000\n",
    "\n",
    "X = df2.iloc[0:numTrain, :NUM_FEATURES]\n",
    "X_array = X.values\n",
    "\n",
    "y = df2.iloc[0:numTrain, NUM_FEATURES:]\n",
    "y_array = y.values\n",
    "\n",
    "y_array_rows = y_array.shape[0]\n",
    "\n",
    "y_integer_classes = np.array([])\n",
    "for i in range(y_array_rows):\n",
    "    row = y_array[i]\n",
    "    index = np.where(row==1)[0][0]\n",
    "    y_integer_classes = np.append(y_integer_classes, int(index))\n",
    "\n",
    "testX = df2.iloc[numTrain:numTrain+numTest, :NUM_FEATURES]\n",
    "testX_array = testX.values\n",
    "testY = df2.iloc[numTrain:numTrain+numTest, NUM_FEATURES:]\n",
    "testY_array = testY.values\n",
    "\n",
    "testy_array_rows = testY_array.shape[0]\n",
    "testy_integer_classes = np.array([])\n",
    "for i in range(testy_array_rows):\n",
    "    row = testY_array[i]\n",
    "    index = np.where(row==1)[0][0]\n",
    "    testy_integer_classes = np.append(testy_integer_classes, int(index))\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "n_estimators = 10\n",
    "print(\"Prediction results: \\n\")\n",
    "predictions = OneVsRestClassifier(BaggingClassifier(LinearSVC(random_state=0, max_iter=1000), n_estimators = n_estimators)).fit(X_array, y_integer_classes).predict(testX_array)\n",
    "print(predictions)\n",
    "print(\"True results: \\n\")\n",
    "print(testy_integer_classes)\n",
    "\n",
    "\n",
    "# Expects list\n",
    "def accuracy(predictions, true_label):\n",
    "    count = 0\n",
    "    total = len(predictions)\n",
    "    for i in range(total):\n",
    "        if predictions[i] == true_label[i]:\n",
    "            count += 1\n",
    "    return float(count) / total\n",
    "\n",
    "pred_list = predictions.tolist()\n",
    "testy_list = testy_integer_classes.tolist()\n",
    "print(\"SVM accuracy: {}%\".format(accuracy(pred_list, testy_list)*100))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
